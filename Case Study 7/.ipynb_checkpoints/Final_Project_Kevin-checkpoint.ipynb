{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Case Study\n",
    "\n",
    "\n",
    "#### Steven Hayden, Kevin Mendonsa, Joe Schueder, Nicole Wittlin  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction: \n",
    "\n",
    "We have been provided a dataset comprising 50 explanatory variables and one response variable with the objective of minimizing cost of the predicted response using provided cost penalties to the business. The dataset contains 160,000 observations. Given the lack of domain knowledge and intrinsic information about the dataset, we will conduct a comprehensive exploratory data analysis (EDA) to understand the charactersitics of the data and the variables. The response variable \"y\" is binary (1,0). \n",
    "\n",
    "No additional information has been provided and therefore the data analysis and processing of the information is critical for delivering optimal results.  We will clearly articulate any assumptions we make in order to reach our conclusions.\n",
    "\n",
    "## Business Imperative:\n",
    "The business imperative for this analysis is to reduce False Negatives as a priority as they appear to have a greater adverse impact to the business in question.  False Positives while important are 50 times less impactful than False Negatives.\n",
    "\n",
    "We have therefore been informed that each False Positive prediction will cost the business \\\\$10 and each False Negative prediction will cost the business \\\\$500. True Positives and True Negatives have no effect on the business cost. Given that False Negatives have a higher cost penalty of (\\\\$500), Recall scores are critical in this analysis. Precision is also important with a cost penalty of \\\\$10. Correct predictions are \"zero cost\". \n",
    "\n",
    "The delivered model must be able to be deployed in a production environment and be generalized for future application of new data.  We will methodically step through various steps from cursory data review to an in-dept data analysis, baselining, modeling, dimensionality reduction, optimization and tuning and conclusions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology and organization of our analysis\n",
    "Our analysis will step through the following stages building upon the conclusions and decisions of previous findings as we transition to an optimal conclusion to support the business imperative for this analysis.\n",
    "\n",
    "### Exploratory Data Analysis (EDA)\n",
    "- Data classes of features\n",
    "- Validate Normality assumptions\n",
    "- Check Cardinality\n",
    "- Missing Data\n",
    "- Validate Independence assumptions\n",
    "    - Pearson's Correlation\n",
    "    - Phi K Correlation\n",
    "- Outliers\n",
    "\n",
    "\n",
    "### Preprocessing\n",
    "- **Data Cleanup**\n",
    "    - Renaming values\n",
    "    - Stripping out special characters\n",
    "    - Conversion of data classes - String to float\n",
    "  \n",
    "\n",
    "- **Imputation Strategy to address missing data**\n",
    "    - Impute or drop\n",
    "    \n",
    "- **One-hot Encoding of categorical variables**\n",
    "\n",
    "\n",
    "- **Standardization**\n",
    "    - MinMax scaling\n",
    "    \n",
    "- **Sampling strategy for testing and training splits**\n",
    "\n",
    "\n",
    "### Establish a Baseline for comparison\n",
    "- Modeling using diverse machine learning model algorithms (rationale for models selected)\n",
    "- Develop a baseline Cost-Benefit Matrix based on provided cost penalties\n",
    " \n",
    "###  Dimensionality Reduction (Feature Reduction)\n",
    "- Recursive feature extraction (Dimensionality Reduction - Occams's Razor)\n",
    " \n",
    "###  Cross Validation using K-fold (Model generalization and optimization)\n",
    " \n",
    "###  Parameter Tuning and Optimization\n",
    " \n",
    "###  Ensembling\n",
    "- Methods use multiple learning algorithms to derive improved predictive performance than a single learning algorithm.\n",
    " \n",
    "###  Error Metrics\n",
    "- Grid Search\n",
    "- Confusion Matrix - Model accuracy and predictive power\n",
    "- ROC-AUC\n",
    "- Recall\n",
    "- Precision\n",
    "- F1 scores\n",
    "\n",
    "###   Conclusion and findings\n",
    "- Cost/Benefits Matrix - Translate into business terms/discovery\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "import itertools\n",
    "from sklearn.feature_selection import RFECV\n",
    "from vecstack import stacking\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from mlxtend.plotting import plot_learning_curves, plot_decision_regions\n",
    "from sklearn.pipeline import Pipeline\n",
    "import itertools\n",
    "from  IPython import display\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "### Load the data to the workspace\n",
    "\n",
    "- Load the data as a data frame and conduct cursory analysis to review\n",
    "    - Shape\n",
    "    - Variable Classes (datatypes)\n",
    "    - Missingness of data (NULL data)\n",
    "    - Unique values for Cardinality\n",
    "\n",
    "For clarity and consistency we will refer to Explanatory variables as Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.54 s\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "%time Business_Data = pd.read_csv('final_project.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 51)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the data\n",
    "Business_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160000 entries, 0 to 159999\n",
      "Data columns (total 51 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   x0      159974 non-null  float64\n",
      " 1   x1      159975 non-null  float64\n",
      " 2   x2      159962 non-null  float64\n",
      " 3   x3      159963 non-null  float64\n",
      " 4   x4      159974 non-null  float64\n",
      " 5   x5      159963 non-null  float64\n",
      " 6   x6      159974 non-null  float64\n",
      " 7   x7      159973 non-null  float64\n",
      " 8   x8      159979 non-null  float64\n",
      " 9   x9      159970 non-null  float64\n",
      " 10  x10     159957 non-null  float64\n",
      " 11  x11     159970 non-null  float64\n",
      " 12  x12     159964 non-null  float64\n",
      " 13  x13     159969 non-null  float64\n",
      " 14  x14     159966 non-null  float64\n",
      " 15  x15     159965 non-null  float64\n",
      " 16  x16     159974 non-null  float64\n",
      " 17  x17     159973 non-null  float64\n",
      " 18  x18     159960 non-null  float64\n",
      " 19  x19     159965 non-null  float64\n",
      " 20  x20     159962 non-null  float64\n",
      " 21  x21     159971 non-null  float64\n",
      " 22  x22     159973 non-null  float64\n",
      " 23  x23     159953 non-null  float64\n",
      " 24  x24     159972 non-null  object \n",
      " 25  x25     159978 non-null  float64\n",
      " 26  x26     159964 non-null  float64\n",
      " 27  x27     159970 non-null  float64\n",
      " 28  x28     159965 non-null  float64\n",
      " 29  x29     159970 non-null  object \n",
      " 30  x30     159970 non-null  object \n",
      " 31  x31     159961 non-null  float64\n",
      " 32  x32     159969 non-null  object \n",
      " 33  x33     159959 non-null  float64\n",
      " 34  x34     159959 non-null  float64\n",
      " 35  x35     159970 non-null  float64\n",
      " 36  x36     159973 non-null  float64\n",
      " 37  x37     159977 non-null  object \n",
      " 38  x38     159969 non-null  float64\n",
      " 39  x39     159977 non-null  float64\n",
      " 40  x40     159964 non-null  float64\n",
      " 41  x41     159960 non-null  float64\n",
      " 42  x42     159974 non-null  float64\n",
      " 43  x43     159963 non-null  float64\n",
      " 44  x44     159960 non-null  float64\n",
      " 45  x45     159971 non-null  float64\n",
      " 46  x46     159969 non-null  float64\n",
      " 47  x47     159963 non-null  float64\n",
      " 48  x48     159968 non-null  float64\n",
      " 49  x49     159968 non-null  float64\n",
      " 50  y       160000 non-null  int64  \n",
      "dtypes: float64(45), int64(1), object(5)\n",
      "memory usage: 62.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data type and not null counts of all the columns\n",
    "Business_Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 categorical features, 45 continuous features of float64 data type.  The response variable is binary classed as an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Analysis of Missing data (NULLs) by feature for determining an imputation strategy\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0     26\n",
       "x1     25\n",
       "x2     38\n",
       "x3     37\n",
       "x4     26\n",
       "x5     37\n",
       "x6     26\n",
       "x7     27\n",
       "x8     21\n",
       "x9     30\n",
       "x10    43\n",
       "x11    30\n",
       "x12    36\n",
       "x13    31\n",
       "x14    34\n",
       "x15    35\n",
       "x16    26\n",
       "x17    27\n",
       "x18    40\n",
       "x19    35\n",
       "x20    38\n",
       "x21    29\n",
       "x22    27\n",
       "x23    47\n",
       "x24    28\n",
       "x25    22\n",
       "x26    36\n",
       "x27    30\n",
       "x28    35\n",
       "x29    30\n",
       "x30    30\n",
       "x31    39\n",
       "x32    31\n",
       "x33    41\n",
       "x34    41\n",
       "x35    30\n",
       "x36    27\n",
       "x37    23\n",
       "x38    31\n",
       "x39    23\n",
       "x40    36\n",
       "x41    40\n",
       "x42    26\n",
       "x43    37\n",
       "x44    40\n",
       "x45    29\n",
       "x46    31\n",
       "x47    37\n",
       "x48    32\n",
       "x49    32\n",
       "y       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get NULL counts by column\n",
    "Business_Data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- TOTAL NULL counts of all features: **1608**\n",
    "- Percentage of NULL values against total data: 1608/160000 => **1.005%**\n",
    "\n",
    "#### The Imputation strategy and actions are listed further below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Inspect all features for Cardinality (Unique classes per variable)\n",
    "This will enable the identification of cardinality in features and also identify candidates for conversion to a categorical data class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Business_Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f260e42007f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Examine Unique values by variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mBusiness_Data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Business_Data' is not defined"
     ]
    }
   ],
   "source": [
    "# Examine Unique values by variable\n",
    "Business_Data.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closer review of the categorical features identified above\n",
    "- A closer analysis reveals that features **x32** and **x37** have special characters. \n",
    "- Additionally feature **x32** has **low cardinality** with only 13 unique classes in 160,000 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes of feature x24:: \n",
      " asia       138965\n",
      "euorpe      16538\n",
      "america      4469\n",
      "NaN            28\n",
      "Name: x24, dtype: int64\n",
      "\n",
      "Unique values of feature x29:: \n",
      " July       45569\n",
      "Jun        41329\n",
      "Aug        29406\n",
      "May        21939\n",
      "sept.      10819\n",
      "Apr         6761\n",
      "Oct         2407\n",
      "Mar         1231\n",
      "Nov          337\n",
      "Feb          140\n",
      "NaN           30\n",
      "Dev           23\n",
      "January        9\n",
      "Name: x29, dtype: int64\n",
      "\n",
      "Unique values of feature x30:: \n",
      " wednesday    101535\n",
      "thurday       29429\n",
      "tuesday       27954\n",
      "friday          564\n",
      "monday          488\n",
      "NaN              30\n",
      "Name: x30, dtype: int64\n",
      "\n",
      "Unique values of feature x32:: \n",
      " 0.01%     40767\n",
      "-0.01%    34094\n",
      "0.0%      33923\n",
      "-0.0%     30492\n",
      "-0.02%     9924\n",
      "0.02%      7987\n",
      "-0.03%     1727\n",
      "0.03%       855\n",
      "-0.04%      138\n",
      "0.04%        55\n",
      "NaN          31\n",
      "-0.05%        6\n",
      "0.05%         1\n",
      "Name: x32, dtype: int64\n",
      "\n",
      "Unique values of response y:: \n",
      " 0    95803\n",
      "1    64197\n",
      "Name: y, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     $1313.96\n",
       "1     $1962.78\n",
       "2      $430.47\n",
       "3    $-2366.29\n",
       "4     $-620.66\n",
       "Name: x37, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review and analyze the Categorical features and response as indicated above\n",
    "print('Unique classes of feature x24:: \\n',Business_Data.x24.value_counts(dropna = False))\n",
    "print('\\nUnique values of feature x29:: \\n',Business_Data.x29.value_counts(dropna = False))\n",
    "print('\\nUnique values of feature x30:: \\n',Business_Data.x30.value_counts(dropna = False))\n",
    "print('\\nUnique values of feature x32:: \\n',Business_Data.x32.value_counts(dropna = False))\n",
    "print('\\nUnique values of response y:: \\n',Business_Data.y.value_counts(dropna = False))\n",
    "\n",
    "Business_Data.x37.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up of categorical features - x32 and x37\n",
    "\n",
    "#### Actions:\n",
    "- Strip feature **x37** off all special characters \n",
    "- Convert feature **x37** to a float data class\n",
    "- Retain feature **x32** as a categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Strip special characters in feature x37\n",
    "\n",
    "Business_Data['x37'] = Business_Data['x37'].str.replace('$','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0%\n",
       "1    -0.02%\n",
       "2    -0.01%\n",
       "3     0.01%\n",
       "4     0.01%\n",
       "Name: x32, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Business_Data.x32.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01%     40767\n",
       "-0.01%    34094\n",
       "0.0%      33923\n",
       "-0.0%     30492\n",
       "-0.02%     9924\n",
       "0.02%      7987\n",
       "-0.03%     1727\n",
       "0.03%       855\n",
       "-0.04%      138\n",
       "0.04%        55\n",
       "-0.05%        6\n",
       "0.05%         1\n",
       "Name: x32, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature x32 class distribution\n",
    "Business_Data.x32.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1313.96\n",
       "1    1962.78\n",
       "2     430.47\n",
       "3   -2366.29\n",
       "4    -620.66\n",
       "Name: x37, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Business_Data.x37.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation strategy\n",
    "\n",
    "Impute the nulls with appropriate values after determining if they are \n",
    "- Missing Completely At Random (MCAR)\n",
    "- Missing At Random (MAR)\n",
    "- Missing Not At Random (MNAR)\n",
    "\n",
    "After discussions with the business, it has been determined that the missing data is to be treated as Missing At Random (MAR).  Furthermore, since almost all the continuous features have a gaussian distribution and meet the assumptions for normality (refer to Pandas Profiling report for additional details), it was agreed to replace NULL values in continuous features with the \"median\" of tyhat feature and drop records with missing values or NANs in categorical values\n",
    "\n",
    "#### Analysis:\n",
    "- TOTAL NULL counts of all features: **1608**\n",
    "- Percentage of total data: 1608/160000 => **1.005%**\n",
    "\n",
    "#### Actions:\n",
    "- Impute missing values of continuous features with the median\n",
    "- Drop missing values for categorical features given the large dataset of 160000 records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame and fill null values as \n",
    "# per the imputation strategy agreed with the business.\n",
    "# Replace missing values in continuous features with the median\n",
    "Business_Data_imputed = Business_Data.apply(lambda x: x if x.dtype == 'object' else x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0      0\n",
       "x1      0\n",
       "x2      0\n",
       "x3      0\n",
       "x4      0\n",
       "x5      0\n",
       "x6      0\n",
       "x7      0\n",
       "x8      0\n",
       "x9      0\n",
       "x10     0\n",
       "x11     0\n",
       "x12     0\n",
       "x13     0\n",
       "x14     0\n",
       "x15     0\n",
       "x16     0\n",
       "x17     0\n",
       "x18     0\n",
       "x19     0\n",
       "x20     0\n",
       "x21     0\n",
       "x22     0\n",
       "x23     0\n",
       "x24    28\n",
       "x25     0\n",
       "x26     0\n",
       "x27     0\n",
       "x28     0\n",
       "x29    30\n",
       "x30    30\n",
       "x31     0\n",
       "x32    31\n",
       "x33     0\n",
       "x34     0\n",
       "x35     0\n",
       "x36     0\n",
       "x37     0\n",
       "x38     0\n",
       "x39     0\n",
       "x40     0\n",
       "x41     0\n",
       "x42     0\n",
       "x43     0\n",
       "x44     0\n",
       "x45     0\n",
       "x46     0\n",
       "x47     0\n",
       "x48     0\n",
       "x49     0\n",
       "y       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Business_Data_imputed.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop NULL observations in categorical features\n",
    "\n",
    "Given the extremely low count of NULLs in the categorical features, dropping these observations still retain 159912 of the 160000 rows. This is approximately **0.07\n",
    "%** of the original data set.  It should likely have little to no impact on the overall analysis.\n",
    "\n",
    "- x24 - $28$\n",
    "- x29 - $30$\n",
    "- x30 - $30$\n",
    "- x32 - $31$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NULLS in categorical features\n",
    "Business_Data_imputed.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up classes in some categorical features for consistency and spelling errors\n",
    "Business_Data_imputed['x24'] = Business_Data_imputed['x24'].replace(['asia', 'euorpe','america'], ['Asia', 'Europe','America'])\n",
    "Business_Data_imputed['x29'] = Business_Data_imputed['x29'].replace(['sept.', 'January','Dev','July'], ['Sep', 'Jan','Dec','Jul'])\n",
    "Business_Data_imputed['x30'] = Business_Data_imputed['x30'].replace(['monday', 'tuesday','wednesday','thurday','friday'], ['Mon', 'Tue','Wed','Thu','Fri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of Business_Data x24:: \n",
      " Asia       138880\n",
      "Europe      16534\n",
      "America      4467\n",
      "Name: x24, dtype: int64\n",
      "\n",
      "Unique values of Business_Data x29:: \n",
      " Jul    45546\n",
      "Jun    41299\n",
      "Aug    29385\n",
      "May    21932\n",
      "Sep    10815\n",
      "Apr     6758\n",
      "Oct     2407\n",
      "Mar     1231\n",
      "Nov      336\n",
      "Feb      140\n",
      "Dec       23\n",
      "Jan        9\n",
      "Name: x29, dtype: int64\n",
      "\n",
      "Unique values of Business_Data x30:: \n",
      " Wed    101473\n",
      "Thu     29413\n",
      "Tue     27943\n",
      "Fri       564\n",
      "Mon       488\n",
      "Name: x30, dtype: int64\n",
      "\n",
      "Unique values of Business_Data x32:: \n",
      " 0.01%     40746\n",
      "-0.01%    34078\n",
      "0.0%      33902\n",
      "-0.0%     30479\n",
      "-0.02%     9916\n",
      "0.02%      7981\n",
      "-0.03%     1726\n",
      "0.03%       854\n",
      "-0.04%      137\n",
      "0.04%        55\n",
      "-0.05%        6\n",
      "0.05%         1\n",
      "Name: x32, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Unique values of Business_Data x24:: \\n',Business_Data_imputed.x24.value_counts(dropna = False))\n",
    "print('\\nUnique values of Business_Data x29:: \\n',Business_Data_imputed.x29.value_counts(dropna = False))\n",
    "print('\\nUnique values of Business_Data x30:: \\n',Business_Data_imputed.x30.value_counts(dropna = False))\n",
    "print('\\nUnique values of Business_Data x32:: \\n',Business_Data_imputed.x32.value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot encoding for Categorical Features\n",
    "\n",
    "One Hot Encoding (ohe) is a popular approach in which a categorical feature is converted to a format enhances the predictive capability of ML algorithms. It works best when the cardinality of the categorical feature is low and is not advisable where there are more than 15 different classes within a single feature. \n",
    "\n",
    "\n",
    "![title](img/OneHotEncoding2.png)\n",
    "\n",
    "Reference: https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding\n",
    "\n",
    "#### Parameter options used for pd.get_dummies\n",
    "- data - Data of which to get dummy indicators \n",
    "    - Parameter setting: **Project_Data_imputed**\n",
    "- prefix_sep - If appending prefix, separator/delimiter to use. Or pass a list or dictionary as with prefix.\n",
    "    - Parameter setting: **\"_\"**\n",
    "- drop_first - Whether to get k-1 dummies out of k categorical levels by removing the first level\n",
    "    - Parameter setting: **True**\n",
    "- columns - Names as list of Categorical features for one hot encoding.\n",
    "    - Parameter setting: **cat_columns** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable \"cat_columns\" to include all features to be encoded\n",
    "cat_columns = ['x24', 'x29', 'x30','x32']\n",
    "\n",
    "# Use the pandas get_dummies function to encode the selected categorical features\n",
    "Business_Data_ohe = pd.get_dummies(Business_Data_imputed, prefix_sep=\"_\", drop_first=True, columns=cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159881 entries, 0 to 159999\n",
      "Data columns (total 75 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   x0           159881 non-null  float64\n",
      " 1   x1           159881 non-null  float64\n",
      " 2   x2           159881 non-null  float64\n",
      " 3   x3           159881 non-null  float64\n",
      " 4   x4           159881 non-null  float64\n",
      " 5   x5           159881 non-null  float64\n",
      " 6   x6           159881 non-null  float64\n",
      " 7   x7           159881 non-null  float64\n",
      " 8   x8           159881 non-null  float64\n",
      " 9   x9           159881 non-null  float64\n",
      " 10  x10          159881 non-null  float64\n",
      " 11  x11          159881 non-null  float64\n",
      " 12  x12          159881 non-null  float64\n",
      " 13  x13          159881 non-null  float64\n",
      " 14  x14          159881 non-null  float64\n",
      " 15  x15          159881 non-null  float64\n",
      " 16  x16          159881 non-null  float64\n",
      " 17  x17          159881 non-null  float64\n",
      " 18  x18          159881 non-null  float64\n",
      " 19  x19          159881 non-null  float64\n",
      " 20  x20          159881 non-null  float64\n",
      " 21  x21          159881 non-null  float64\n",
      " 22  x22          159881 non-null  float64\n",
      " 23  x23          159881 non-null  float64\n",
      " 24  x25          159881 non-null  float64\n",
      " 25  x26          159881 non-null  float64\n",
      " 26  x27          159881 non-null  float64\n",
      " 27  x28          159881 non-null  float64\n",
      " 28  x31          159881 non-null  float64\n",
      " 29  x33          159881 non-null  float64\n",
      " 30  x34          159881 non-null  float64\n",
      " 31  x35          159881 non-null  float64\n",
      " 32  x36          159881 non-null  float64\n",
      " 33  x37          159881 non-null  float64\n",
      " 34  x38          159881 non-null  float64\n",
      " 35  x39          159881 non-null  float64\n",
      " 36  x40          159881 non-null  float64\n",
      " 37  x41          159881 non-null  float64\n",
      " 38  x42          159881 non-null  float64\n",
      " 39  x43          159881 non-null  float64\n",
      " 40  x44          159881 non-null  float64\n",
      " 41  x45          159881 non-null  float64\n",
      " 42  x46          159881 non-null  float64\n",
      " 43  x47          159881 non-null  float64\n",
      " 44  x48          159881 non-null  float64\n",
      " 45  x49          159881 non-null  float64\n",
      " 46  y            159881 non-null  int64  \n",
      " 47  x24__Asia    159881 non-null  uint8  \n",
      " 48  x24__Europe  159881 non-null  uint8  \n",
      " 49  x29__Aug     159881 non-null  uint8  \n",
      " 50  x29__Dec     159881 non-null  uint8  \n",
      " 51  x29__Feb     159881 non-null  uint8  \n",
      " 52  x29__Jan     159881 non-null  uint8  \n",
      " 53  x29__Jul     159881 non-null  uint8  \n",
      " 54  x29__Jun     159881 non-null  uint8  \n",
      " 55  x29__Mar     159881 non-null  uint8  \n",
      " 56  x29__May     159881 non-null  uint8  \n",
      " 57  x29__Nov     159881 non-null  uint8  \n",
      " 58  x29__Oct     159881 non-null  uint8  \n",
      " 59  x29__Sep     159881 non-null  uint8  \n",
      " 60  x30__Mon     159881 non-null  uint8  \n",
      " 61  x30__Thu     159881 non-null  uint8  \n",
      " 62  x30__Tue     159881 non-null  uint8  \n",
      " 63  x30__Wed     159881 non-null  uint8  \n",
      " 64  x32__-0.01%  159881 non-null  uint8  \n",
      " 65  x32__-0.02%  159881 non-null  uint8  \n",
      " 66  x32__-0.03%  159881 non-null  uint8  \n",
      " 67  x32__-0.04%  159881 non-null  uint8  \n",
      " 68  x32__-0.05%  159881 non-null  uint8  \n",
      " 69  x32__0.0%    159881 non-null  uint8  \n",
      " 70  x32__0.01%   159881 non-null  uint8  \n",
      " 71  x32__0.02%   159881 non-null  uint8  \n",
      " 72  x32__0.03%   159881 non-null  uint8  \n",
      " 73  x32__0.04%   159881 non-null  uint8  \n",
      " 74  x32__0.05%   159881 non-null  uint8  \n",
      "dtypes: float64(46), int64(1), uint8(28)\n",
      "memory usage: 62.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Review the results of the encoding operation\n",
    "Business_Data_ohe.isnull().sum()\n",
    "Business_Data_ohe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "We used correlation plot to identify the attributes in the original dataset that appeared to be highly collinear. In other words, one predictor feature in the regression model can be linearly predicted from the others with a substantial degree of accuracy.\n",
    "\n",
    "\n",
    "**Pearson's Correlation**\n",
    "\n",
    "The Pearson correlation coefficient is used to measure the strength of a linear association between two variables, where the value r = 1 means a perfect positive correlation and the value r = -1 means a perfect negataive correlation. It inofrms whether a statistically significant linear relationship exists between two continuous variables. The strength of a linear relationship (i.e., how close the relationship is to being a perfectly straight line) \n",
    "\n",
    "(Reference: https://www.dummies.com/education/math/statistics/how-to-interpret-a-correlation-coefficient-r/)\n",
    "\n",
    "Interpretation of Pearson's coefficient.\n",
    "* Exactly –1. A perfect downhill (negative) linear relationship\n",
    "\n",
    "* –0.70. A strong downhill (negative) linear relationship\n",
    "\n",
    "* –0.50. A moderate downhill (negative) relationship\n",
    "\n",
    "* –0.30. A weak downhill (negative) linear relationship\n",
    "\n",
    "* 0. No linear relationship\n",
    "\n",
    "* +0.30. A weak uphill (positive) linear relationship\n",
    "\n",
    "* +0.50. A moderate uphill (positive) relationship\n",
    "\n",
    "* +0.70. A strong uphill (positive) linear relationship\n",
    "\n",
    "* Exactly +1. A perfect uphill (positive) linear relationship\n",
    "\n",
    "![title](img/PearsonCorrelation.png) \n",
    "\n",
    "Since the data set is large, the correlation plot was not very informative when plotted using all the features. So, we filtered only those features that had a score greater than 0.8 in the below figure. Based on the analysis, features $x6$ and $x41$ were excluded as they were highly correlated with $x2$ and $x38$ respectively (corr = 1 were excluded to avoid displaying self correlated features).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e4e98cbec8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAEDCAYAAACWDNcwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAbUUlEQVR4nO3deZRU9Zn/8fenG7CbTRRZZYuKjiHuCuOGRowxopIxZiSZ0cSojEYTM2YbTSZnTCYTs5lo9KcyLnHJxLhHRY24Q9xABQRxBUEERNwAWaS7nt8fdWmLtru6eqlb1cXndc49VN3le5+6p3n66e/93m8pIjAzs3RUlToAM7MtiZOumVmKnHTNzFLkpGtmliInXTOzFDnpmpmlyEnXrBORdLWkFZLmdlB79ZJmJcudrThuG0m3S5oj6WlJn2lmv8MkPStprqRrJXXJd7ykXXLimSVplaTvdMDnvE/S+5Lubm9b7Y7F43TNOg9JY4E1wHUR0WSia2V7ayKiZwv7vB4RIxqt+zWwJiLOl/QPwKURMa7RPlXAImBcRLws6afAooi4qsDjq4E3gTERsaidn3Mc0B34t4g4uj1ttZcrXbNOJCIeA97NXSdpx6SSe0bStCSJFdungQeTmF4ERkga0GifvsCGiHg5eT8V+FIrjh8HvLYp4bbnc0bEg8Dqwj9e8TjpmnV+k4FvRcQ+wPeA/9eKY2skzZT0pKQvtuK42cBxAJJGA8OBIY32WQl0lbRv8v54YGgrjp8I/DnnfXs+Z9noUuoAzKztJPUEDgBulrRp9VbJtuOAnzZx2JsR8fnk9bCIWCppB+AhSc9HxGuSLgUOTPYZLGlW8vrmiPg5cAFwUbL+eeA5oC73JBERkiYCv5O0FXB/zj55j5fUDTgWOLeDPmfZcNI169yqgPcjYs/GGyLiNuC2fAdHxNLk3wWSHgH2Ivsn/Zmb9kn6dPdsdNwq4ORku4CFydK4/SeAg5P9jgB2LvD4LwDPRsRbHfE5y4m7F8w6sSR5LZT0ZcgmMEl7FHJsMoJgU7W4HdnK9oUCj+2TVKMApwKPJbE03q9/8u9WwA+Byws8/ivkdC2053OWGydds05E0p+BJ4BdJC2RdArwL8ApkmYD84AJBTa3KzAzOe5h4IKIKCjpJsfOk/Qi2ar07JwY75E0OHn7fUnzgTnAXRHxUAHHdwc+xyer17Z+TiRNA24GxiXXrWTdDh4yZmaWIle6ZmYpSuNGmktpMyuUWt4lvylddyk454zf+FK7z9darnTNzFLkIWNmVlHUNfXitVWcdM2solTXVpc6hLycdM2solR1caVrZpYady+YmaXIla6ZWYpc6ZqZpciVrplZiqq7lffjB066ZlZRVOVK18wsNap2pWtmlpqqale6ZmapcfeCmVmKfCPNzCxFqnLSNTNLjbsXzMxS5BtpZmYpcqVrZpYi9+mamaWouquTrplZaty9YGaWIncvmJmlyJWumVmKnHTNzFJU1cXfBmxmlppyfzgib4+zpN6Sdmxi/e7FC8nMrO1UpYKXUmg26Ur6Z+BF4FZJ8yTtl7P5j/kalTRJ0kxJMydPntwxkZqZFUBVVQUvpZCve+E8YJ+IWCZpNHC9pPMi4jYg76+IiJgMbMq20TGhmpm1rDPfSKuOiGUAEfG0pM8Cd0saghOpmZWpzpx0V0vaMSJeA0gq3kOBO4BRaQRnZtZanXn0whlAlaRPR8QLABGxWtKRwMRUojMza6VyfyKt2egiYnZEvALcJOmHyqoFLgS+mVqEZmatIRW+lEAhvxLGAEOBx4EZwFLgwGIGZWbWVuU+ZKyQhyM2AuuAWqAGWBgRmaJGZWbWRp22eyHHDLJJdz/gIOArkm4palRmZm1UCZXuKRExM3m9HJgg6cQixmRm1madefQCADkJN3fd9cUJx8ysfTrzOF0zs86nzPt0nXTNrKKoREPBCuWka2YVpSNHL0h6HVgN1AN1EbFvo+0CLgKOAtYCX4+IZ/O16aRrZhVFHX8j7bMRsbKZbV8ARibLGOCy5N9mOemaWUVJ+UbaBOC6iAjgSUl9JA3aNFlYU8q7x9nMrJWkqlYsH8/9nSyTGjUXwP2SnmliG8D2wBs575ck65rlStfMKksrKt1Gc3835cCIWCqpPzBV0osR8VjO9qZOlnfqW1e6ZlZROvKbIyJiafLvCuB2YHSjXZaQnZtmkyFk56dplpOumVWUjnoMWFIPSb02vQaOAOY22u1O4KRkFsZ/BD7I158L7l4wswqj6g4bvTAAuD0Z99sF+L+IuE/S6QARcTlwD9nhYq+SHTJ2ckuNOumaWWXpoHG6EbEA2KOJ9ZfnvA7gzNa066RrZhXFT6SZmaXJcy+YmaXHs4yZmaVJW3ile9Axjxb7FJ3K9LsOKXUIZhWtA0cvFIUrXTOrLO5eMDNLT7l/MaWTrplVFg8ZMzNLkStdM7P0+EaamVmatvQhY2ZmqfLoBTOz9MiVrplZilzpmpmlyJWumVmKPHrBzCxFrnTNzFLkPl0zsxS50jUzS5HnXjAzS5HnXjAzS1GVRy+YmaXHla6ZWYrcp2tmliKPXjAzS5ErXTOz9IQfAzYzS5G7FzrGmL234ezTdqKqStw9dRk33PLGZtt79ejCuWfvwuCBNXy0McMvLnqJhYvXAvDlY7bnmM8PQoI7/7aMm+98E4CdRvTge2fuTG1NFctXbOD838xn7bp6PndIf7563NCGtncc0YNvfOcZXl34YXof2Mzaxkm3/aqq4JzTR/Lv/zmHFe9s4MoL92b6U+/w+htrG/Y58Z+H8cqCNZz3P/MYNqSWc04fyXd+PIdPDevOMZ8fxGnffZa6jRl+e/7uPDHjXZYsW8cPv70zl169gFlzP2D84QP56nFDufJPrzP10RVMfXQFADsM78EFPx7lhGvWSUSZ9+mW96+ExK4je7Nk2TqWvrWeurrggcdWcNCYvpvtM2Jod56Z8x4Ai5esY1D/Grbp05URQ7sz76VVbNiQoT4Dz819n7H7bwfAsO27M2vuBwDMmPUehxyw3SfOffjY/jzw2Ioif0Iz6zCqKnwpgWbPKmmYpJrktSSdLOkPks6QlGqF3K9vN1as3NDw/u13NtCv71ab7fPqwg8Zu38/AHYd2YsB/Wvo33crFixay56jtqZ3ry5stVUV++/bl/7bZY9dsOjDhuT92QP7MWC7zdsEGHdwv4aq18w6AanwpQTypfp7crZfAIwHngL2Aybna1TSJEkzJc1cvuiudgfZ1LWJ2Pz9DbcsplfPLlxz0T586ZjteWXBaurrg0VL1nLDrW/wu5/tzm//azdeXbiG+kz24F9c/BLHjR/MVb/bm+611Wys27zRT+/ci/Ub6hv6hs2s/EV1dcFLKeSrWKsiYlO2ORzYLyIywA2SZudrNCImkyTmg455NPLtW4gVKz9qqE4B+vXdipXvbthsn7Xr6vnFRS81vL/5yjEsfWs9AFOmLmfK1OUATDrxU7z9TvbYxUvWcc5Pngdg6OBa9t9v283aHDe2Pw889nZ7wzezNJX5jbR80b0h6bDk9evAUABJfZs9okhefGUVQwfXMmhADV26iMPH9ufvT7+z2T49e1TTpUu2JD7miIHMnvc+a9fVA9Bn664ADOi3FYccsB0PJN0Fm9ZL8LUThvHXe5c1tCdluxwedH+uWacSqip4KYV8le6pwHWS/gv4AJgl6TlgG+CcFGJrUJ+BCy9/lQvP342qKjHlgeUsXLyWCUcOAuCv9y1j+JAe/PicXchk4PXFH3LBxS83HP/zc0fRu1cX6uuDCy97hdUf1gHwubH9OW78YAAefWIlUx5Y3nDMnqO25u2VGxqqZTPrJMp89IKicedo4x2k3YAdyCboJcAMYGxEPFLICTqie6GSTL/rkFKHYFbO2p0xVz89peCc02v0+BbPJ6kamAm8GRFHN9p2KPBXYGGy6raI+Gm+9goZhfBn4HrgV0ANcBGwL7B/AceamaWr4+fTPRuYD/RuZvu0xsk4n0I6NcaQ7c99nGyVuxQ4sNATmJmlKaSCl5ZIGkJ25NaVHRVfIUl3I7AOqCVb6S5MRjGYmZWfVjwckTu8NVkmNWrt98APgHw5b39JsyXdK2lUS+EV0r0wg2yfxX5AX+AKScdHxPEFHGtmlqpoRbdw7vDWxiQdDayIiGeSvtumPAsMj4g1ko4C7gBG5jtnIZXuKRHxk4jYGBHLI2IC2SRsZlZ2OnDI2IHAsZJeB24EDpN0w2bnilgVEWuS1/cAXSV9cj6BHC2eNSJmNrHu+paOMzMriQ6aeyEizo2IIRExApgIPBQR/7rZqaSBUrZzWNJosjn1nU80lqNTzDJmZlaoTJG/DVjS6QARcTlwPHCGpDqy974mRgvjcJ10zayyFOHhiOS5hEeS15fnrL8EuKQ1bTnpmllFKdXjvYVy0jWzitKa0Qul4KRrZhXFla6ZWZrKfMIbJ10zqygZ+SvYzcxS4+4FM7MU+UaamVmKXOmamaWokCkbS8lJ18wqim+kmZmlyH26ZmYpcp+umVmKXOmamaXIla6ZWYq2+Ep3+l2HFPsUZmYNMgV9C1npuNI1s4oSTrpmZunZ4rsXzMzS5KRrZpYiJ10zsxQ56ZqZpSgTvpFmZpYaV7pmZily0jUzS1GEk66ZWWoyrnTNzNLjG2lmZilyn66ZWYrcp2tmliJXumZmKXKla2aWokypA2iBk66ZVRSPXjAzS5G7F8zMUuQbaWZmKcpEqSPIr7w7P8zMWilQwUshJFVLek7S3U1sk6SLJb0qaY6kvVtqz5WumVWUIvTpng3MB3o3se0LwMhkGQNclvzbLFe6ZlZR6kMFLy2RNAQYD1zZzC4TgOsi60mgj6RB+dp00jWzihKhghdJkyTNzFkmNWru98APaH747/bAGznvlyTrmuXuBTOrKNGKG2kRMRmY3NQ2SUcDKyLiGUmHNtNEU+Vy3giarXQl7SDpakn/LamnpP+VNFfSzZJG5Gs097fH5MlNfh4zs6LowBtpBwLHSnoduBE4TNINjfZZAgzNeT8EWJqvUUUzvxYkPQb8Gdga+FfgGuAm4AjgXyLisJYiTpT5AA4zKyPtvgt236yPCs45R+7ZraDzJZXu9yLi6EbrxwNnAUeRvYF2cUSMztdWvu6FXhFxWdLwNyPit8n6qySdVUigZmZpy2SK+3CEpNMBIuJy4B6yCfdVYC1wckvH50u6GUk7k610u0vaNyJmStoJqG535GZmRVCMr+uJiEeAR5LXl+esD+DM1rSVL+n+ALiL7F27LwLnStqD7Fi101oVsZlZSlpzI60Umk26EfEgsEvOqumStgPei4j6okdmZtYG5T7hTd5xupIGShqYvO4HjGXzRGxmVlYyUfhSCvmGjP0b8ATwpKQzgLuBo4HbJZ2SUnxmZq0SUfhSCvn6dM8CRgG1wCJgp4hYLmkb4GHgqhTiMzNrlUIe7y2lfEl3Y0SsBdZKei0ilgNExHuSyryr2sy2VJ32RhrZIWNdI2Ij2QkfAJBUg+dsMLMy1ZmT7nEAkj4dES/krN8W+F5RozIza6NMmXcvNFuxRsTipMq9SdIPk8l6a4FzgZ+mFqGZWSuU+420QroJxpCd0OFxYAbZyRwOLGZQZmZtVZ8pfCmFQqZ23AisIzuKoQZYGBHl/tXyZraF6tQPRyRmkE26+wEHAV+RdEtRozIza6Ny714opNI9JSJmJq+XAxMknVjEmMzM2qzcvw24xaSbk3Bz111fnHDMzNqnMw8ZMzPrdJx0zcxSVKpRCYVy0jWzipJx0jUzS4+7F8zMUuSka2aWok4/ZMzMrDOJVpW66T+95qRrZhWlvsy/wdFJ18wqivt0zZowpau/3zTX+I0vlTqEiuE+XTOzFLnSNTNLUbSq1PWNNDOzdvFjwGZmKcqUeaeuk66ZVRT36ZqZpchJ18wsRZkyz7pOumZWUcr9a3OddM2sotTXu9I1M0tN6ya8SZ+TrplVlDIfMeaka2aVpXVPpKXPSdfMKkqZ9y5QVeoAzMw6UiYTBS/5SKqR9LSk2ZLmSTq/iX0OlfSBpFnJ8pOW4nOla2YVJdNxoxc2AIdFxBpJXYHpku6NiCcb7TctIo4utFEnXTOrKB31cERkh0GsSd52TZZ2N+7uBTOrKBFR8CJpkqSZOcuk3LYkVUuaBawApkbEU02ccv+kC+JeSaNais+VrplVlNbMMhYRk4HJebbXA3tK6gPcLukzETE3Z5dngeFJF8RRwB3AyHzndKVrZhUlovCl8DbjfeAR4MhG61dFxJrk9T1AV0nb5WvLSdfMKkp9fabgJR9J/ZIKF0m1wOHAi432GShJyevRZHPqO/nadfeCmVWUDnw4YhBwraRqssn0poi4W9LpABFxOXA8cIakOmAdMDFaeA7ZSdfMKkpHJd2ImAPs1cT6y3NeXwJc0pp23b1gnVq/Iw7mkLn3cej8+9nx+6d9YnuXPr3Z5+ZLOPjZOznw8ZvpOerjexwjvnUSY5+7i7Gz7mbEt7/WsL7X7rtwwLQbOfi5O9n39svo0qsHAOrShT2uvoCDn7uTQ+bcw44/mPSJ81npZaLwpRScdK3zqqpi1MU/4eljTuXR3cczeOLR9Nx1x8122ek/TmfV7PlM2/tYZp38Q0Zd+CMAeo4aybBvfJnpB3yZaftMYMBRh9J9p+EA7H7Fz3nxvN8yba9jWf7XB9jhu6cCMOj4I6nq1o1pex3LtDHHMey0E6gdvn26n9laFJkoeCkFJ13rtPqM3p21ry1i3cIlxMaNLP3LFAYcM26zfXrtuiMrH84+QPThSwuoHb493fr3pec/7Mh7T88ms249UV/PO4/NYOCEzwHQY+dP8e60GQCsfODvDPynI7KNRVDdoxZVV1NdW0Pmo43UrVqDlZfWjNMtBSdd67RqBg9g3ZLlDe/Xv/kWNdsP2GyfVXNeZOAXs8l06/12o3b4YGqGDGTNvJfZ9qB96bptH6pqa+j/hbHUDh0IwJp5Lzck70HHH0nt0EEALLv1b9R/uI5xb0znsAUPs+B3V7PxvQ/S+KjWCh01eqFY2pR0JTU7mNgsNdmROptrVL289qvJdN2mNwfNvIMRZ57Iqlnzibo61ry4gAW/uZIx913N6ClXsmrOS2Tq6gGYfdqPGH7GVznoqVvp0rMHmY8+ArKVdWQyPDjsYB4eOY4dvvMNaj81pOgf01qn3LsXmh29IGnb5jYBR+VrNHmUbhLAFVdcwaRJvuFgHW/9m8upHTKw4X3N9gNYv3TFZvvUrf6QOaee1/D+s688yLqFSwB445pbeOOaWwDY5Wf/zvo33wKy3RBPH3UKAD1GjqD/UYcCMHji0bz9t2lEXR0fvf0u7z3xLH322a2hPSsPnXk+3beBRWST7CaRvO+fr9FGj9aV9xWwTuuDGc/TY6cR1I4Ywvo332LwCeN57sTvbrZPl617Ub92PbFxI0NP+TLvTp9J3eoPAejWb1s+evtdaoYOYuAXj+DvB5+w2XokdjrvDBZNvhGAdYuX0fezY3jzT3+lunstfUbvwcKLr033Q1uLOvO3AS8AxkXE4sYbJL1RvJDMChP19cw9+6eMnnIlqq5myR9vZc0LrzJs0kQAFk++kZ677sieV/+SqM+wZv6rzJ70o4bj97npD3Tdtg9RV8fcb59P3furgGxFO/z0rwKw/I6pLPnjrQAsuuxP7HHlLxg7626QWHLtbax+/qWUP7W1pNwrXTV3B0/SmcD0iJjdxLZvRcQfCjxHeV8BK4kpXXcpdQhlZfxGJ+9EEx31rXPSfy4rOOdc97NB7T5fazVb6UbEpXm2FZpwzcxSVV9XmlEJhWrV6AVJ/1OsQMzMOkK5j9PNN3rh4sargBMl9QSIiG8XMzAzs7aITHlXuvlupB1Hdv7I+/m4n2Ui8EyRYzIza7PWTGJeCvm6F3YFVpKdtPeBiLgWWB0R1yavzczKTqftXoiI1cB3JO0N3CBpCn5s2MzKXKYCbqStBw4jO0HvdMh+13sRYzIza7NMZApeSqGQScxvAq4Dfg1cI+kPwL7A/sUMzMysLcr94YhCKt0xwDDgceBpYClwYDGDMjNrq0474U2OjWS7FmqBGmBhRInqcjOzFpTqBlmhCql0Z5BNuvsBBwFfkXRLUaMyM2ujTCZT8FIKhVS6p0TEzOT1cmCCpBOLGJOZWZtl6utLHUJeLSbdnISbu+764oRjZtY+5X4jzV/BbmYVxUnXzCxFpRp/WygnXTOrKK50zcxS1JlnGTMz63Q6/egFM7POpNyndnTSNbOK4u4FM7MU+UaamVmKyn1qGCddM6sombryvpGmcp+Rp6NImhQRk0sdRznwtfiYr8XHfC3SsSV9/c6kUgdQRnwtPuZr8TFfixRsSUnXzKzknHTNzFK0JSVd91V9zNfiY74WH/O1SMEWcyPNzKwcbEmVrplZyTnpmpmlaItIupL2lPSEpHmS5kg6odQxlZKkYZLulzRf0guSRpQ6prRIGi7pGUmzkp+H03O2jZP0bLJtuqSdShlrWiT1lvSmpEty1p0l6VVJIWm7UsZXabaIPl1JOwMREa9IGgw8A+waEe+XOLSSkPQI8POImCqpJ5CJiLUlDisVkrqR/bnfkHz2ucABEbFU0svAhIiYL+mbwOiI+Hop402DpIuAfsC7EXFWsm4v4D3gEWDfiFhZuggrS8VVupL2S6rZGkk9JM0DukXEKwARsRRYQfaHrKI1dS0k7Q50iYipABGxplITbjM/CztHxIZkl63Y/P9AAL2T11sDS1MMt6ia+Vn4jKR9gAHA/bn7R8RzEfF6SYKtcBVZ6Ur6b6AGqAWWRMQvcraNBq4FRkW5z4zRARpfC2A+cCrwEfAp4AHgPyKivB9Yb6OmfhYkDQWmADsB34+IS5N9DwbuANYBq4B/jIhVpYm84zXxs/BL4CHgRGAc2Yr2rEbHvI4r3Q5VqUm3GzADWE/2T8f6ZP0gsn8ufS0inixdhOlpfC2AfwKuAvYCFgN/Ae6JiKtKFmQRNfezkGwbTDbJHhMRb0m6DfhlRDwl6fvALhFxakkCL4ImfhbOALpHxK8kfR0n3VRUXPdCYlugJ9CL7G92JPUmW938eEtJuInG12IJ8FxELIiIOrJJZ+8Sxldsn/hZ2CTpapoHHCypH7BHRDyVbP4L2cRUSRpfi/2Bs5LE+hvgJEkXlC68LUOlVrp3AjeS/fN5EHAOcC9wV0T8vpSxpa2Ja3E28CxweES8LekaYOamP7ErTROf/wLgnYhYJ2kb4CngS2S7XZaTrYZflnQKcFREfKlEoXe4xtcit6p1pZueiptPV9JJQF1E/J+kauBxYCIwFuib/HABfD0iZpUozFQ0cy0OAb4HPChJZEdy/G8JwyyaZj7/KODXkgIQ8JuIeD7Z/zTgVkkZsnfuv1Gi0DtcU9dC0mER8VAz+38b+AEwEJgj6Z5K6moppYqsdM3MylWl9umamZUlJ10zsxQ56ZqZpchJ18wsRU66ZmYpctI1M0uRk66ZWYr+P7knWDJM9nkNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = Business_Data_ohe_scaled.corr()\n",
    "\n",
    "kot = corr[(corr>=.8) & (corr<1)]\n",
    "kot.dropna(axis=0, how='all', inplace = True)\n",
    "kot.dropna(axis=1, how='all', inplace = True)\n",
    "\n",
    "matrix = np.triu(kot)\n",
    "sns.heatmap(kot, annot=True, fmt='.4g', cmap= 'coolwarm', mask = matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x2</th>\n",
       "      <th>x6</th>\n",
       "      <th>x38</th>\n",
       "      <th>x41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>0.999731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x2        x6       x38       x41\n",
       "x2        NaN  0.999731       NaN       NaN\n",
       "x6   0.999731       NaN       NaN       NaN\n",
       "x38       NaN       NaN       NaN  0.999755\n",
       "x41       NaN       NaN  0.999755       NaN"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization of the data - Scaling\n",
    "\n",
    "A pre-processing step applied to independent features in a dataset. Primarily it normalizes within a particular range. It may also aid in accelerating the computations in an algorithm. The Features have been scaled to a mean of 0 and variance of 1 to improve accuracy of the classification models.\n",
    "\n",
    "*fit_transform* within MinMaxScaler() function fits to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Business_Data_ohe_scaled = pd.DataFrame(scaler.fit_transform(Business_Data_ohe), columns=Business_Data_ohe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x32__-0.02%</th>\n",
       "      <th>x32__-0.03%</th>\n",
       "      <th>x32__-0.04%</th>\n",
       "      <th>x32__-0.05%</th>\n",
       "      <th>x32__0.0%</th>\n",
       "      <th>x32__0.01%</th>\n",
       "      <th>x32__0.02%</th>\n",
       "      <th>x32__0.03%</th>\n",
       "      <th>x32__0.04%</th>\n",
       "      <th>x32__0.05%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "      <td>159881.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.498395</td>\n",
       "      <td>0.484268</td>\n",
       "      <td>0.473770</td>\n",
       "      <td>0.476629</td>\n",
       "      <td>0.520278</td>\n",
       "      <td>0.487751</td>\n",
       "      <td>0.473779</td>\n",
       "      <td>0.525666</td>\n",
       "      <td>0.490752</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062021</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.212045</td>\n",
       "      <td>0.254852</td>\n",
       "      <td>0.049918</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.116206</td>\n",
       "      <td>0.116829</td>\n",
       "      <td>0.107960</td>\n",
       "      <td>0.108415</td>\n",
       "      <td>0.116644</td>\n",
       "      <td>0.110552</td>\n",
       "      <td>0.107965</td>\n",
       "      <td>0.092364</td>\n",
       "      <td>0.115988</td>\n",
       "      <td>0.114781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241195</td>\n",
       "      <td>0.103340</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.408758</td>\n",
       "      <td>0.435779</td>\n",
       "      <td>0.217777</td>\n",
       "      <td>0.072890</td>\n",
       "      <td>0.018544</td>\n",
       "      <td>0.002501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.419959</td>\n",
       "      <td>0.405735</td>\n",
       "      <td>0.400452</td>\n",
       "      <td>0.403659</td>\n",
       "      <td>0.441475</td>\n",
       "      <td>0.413356</td>\n",
       "      <td>0.400452</td>\n",
       "      <td>0.466303</td>\n",
       "      <td>0.412554</td>\n",
       "      <td>0.428507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.498073</td>\n",
       "      <td>0.484334</td>\n",
       "      <td>0.472208</td>\n",
       "      <td>0.476525</td>\n",
       "      <td>0.520300</td>\n",
       "      <td>0.487755</td>\n",
       "      <td>0.472214</td>\n",
       "      <td>0.527888</td>\n",
       "      <td>0.490927</td>\n",
       "      <td>0.505554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.576522</td>\n",
       "      <td>0.563162</td>\n",
       "      <td>0.547144</td>\n",
       "      <td>0.550157</td>\n",
       "      <td>0.598995</td>\n",
       "      <td>0.562359</td>\n",
       "      <td>0.547160</td>\n",
       "      <td>0.585873</td>\n",
       "      <td>0.568981</td>\n",
       "      <td>0.583199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x0             x1             x2             x3  \\\n",
       "count  159881.000000  159881.000000  159881.000000  159881.000000   \n",
       "mean        0.498395       0.484268       0.473770       0.476629   \n",
       "std         0.116206       0.116829       0.107960       0.108415   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.419959       0.405735       0.400452       0.403659   \n",
       "50%         0.498073       0.484334       0.472208       0.476525   \n",
       "75%         0.576522       0.563162       0.547144       0.550157   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  x4             x5             x6             x7  \\\n",
       "count  159881.000000  159881.000000  159881.000000  159881.000000   \n",
       "mean        0.520278       0.487751       0.473779       0.525666   \n",
       "std         0.116644       0.110552       0.107965       0.092364   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.441475       0.413356       0.400452       0.466303   \n",
       "50%         0.520300       0.487755       0.472214       0.527888   \n",
       "75%         0.598995       0.562359       0.547160       0.585873   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  x8             x9  ...    x32__-0.02%    x32__-0.03%  \\\n",
       "count  159881.000000  159881.000000  ...  159881.000000  159881.000000   \n",
       "mean        0.490752       0.505541  ...       0.062021       0.010796   \n",
       "std         0.115988       0.114781  ...       0.241195       0.103340   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.412554       0.428507  ...       0.000000       0.000000   \n",
       "50%         0.490927       0.505554  ...       0.000000       0.000000   \n",
       "75%         0.568981       0.583199  ...       0.000000       0.000000   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "         x32__-0.04%    x32__-0.05%      x32__0.0%     x32__0.01%  \\\n",
       "count  159881.000000  159881.000000  159881.000000  159881.000000   \n",
       "mean        0.000857       0.000038       0.212045       0.254852   \n",
       "std         0.029260       0.006126       0.408758       0.435779   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          x32__0.02%     x32__0.03%     x32__0.04%     x32__0.05%  \n",
       "count  159881.000000  159881.000000  159881.000000  159881.000000  \n",
       "mean        0.049918       0.005341       0.000344       0.000006  \n",
       "std         0.217777       0.072890       0.018544       0.002501  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 75 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Business_Data_ohe_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features 'x6', 'x41' due to high correlation as identified above\n",
    "Project_Data_final = Business_Data_ohe_scaled.drop(['x6', 'x41'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data set into Response and Explanatory Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Project_Data_final.drop(columns=['y'], axis=1)\n",
    "y = Project_Data_final.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "This technique provides us a way of voluntarily holding back part of the data to test whether the model works. If we use our entire dataset to train the model, then the model will alway predict the correct category for any entry in the data set. This process of setting aside a part of the dataset voluntarily to evaluate the model stops the model from being too optimistic when predicting the outcome. Training the model on the entire data set could also lead to data snooping bias. This kind of bias results from refining too many parameters to improve the model's performance on a data set. In our analysis, we will split the data into training and test data sets (75:25) randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the response ratio in Train-Test split\n",
    "\n",
    "Let's check the ratio of the response variables and compare it with that of the Train and Test dataset. The below results confirm that the ratio is retained and hence we can proceed with K-Fold Cross-Validation(CV) instead of Stratifid K-Fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4925324270391618"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Project_Data_final['y']==0)/sum(Project_Data_final['y']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4857587064676616"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test==0)/sum(y_test==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.494798601864181"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train==0)/sum(y_train==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Establish the baseline Cost-Benefit matrix before tuning and optimizations\n",
    "\n",
    "- Use the complete data set and selective models with default parameters.\n",
    "- Establish a confusion matrix with classification results and model accuracy scores. \n",
    "- Create a custom function **confusion_mat** to capture, display and compare the confusion and classification results. \n",
    "- Use the true False Positives(FP) and False Negatives(FN) for the case counts to calculate the resulting business cost.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the default parameters for the models to be used below\n",
    "rand_state = 10\n",
    "n_iterations = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### K-fold Cross-Validation to improve model generalization for future applicability\n",
    "\n",
    "- This statistical method is used to evaluate model generalization performance\n",
    "- Provides greater stability and is more robust than using a simple split of a dataset into train and test sets.\n",
    "- The algorithm splits the dataset multiple times training the model repeatedly on each of the splits.\n",
    "- KFold divides the dataset into groups of equal sized samples (if possible), called folds.\n",
    "- The prediction function uses these folds for learning, with the fold left out used for testing.\n",
    "\n",
    "![title](img/KFoldCV.png) \n",
    "\n",
    "Reference: https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538\n",
    "\n",
    "We adopted the k-fold cross-validation approach for our analysis with the following parameters.\n",
    "\n",
    "Parameters for k-fold CV:\n",
    "- **n_splitsint** - Number of folds\n",
    "    - Parameter selected: **5**\n",
    "- **random_state** - random_state is the seed used by the random number generator\n",
    "    - Parameter selected: **10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the cross validation parameters to be used in the models\n",
    "cv = KFold(n_splits=n_iterations, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>False_Positives</th>\n",
       "      <th>False_Negatives</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Classifier, Features, Parameters, False_Positives, False_Negatives, Cost]\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe to capture the results of the baseline models below\n",
    "results_df = pd.DataFrame(columns=['Classifier', 'Features', 'Parameters', 'False_Positives', 'False_Negatives', 'Cost'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom function to create a confusion matrix and print the results of the base models\n",
    "def confusion_mat(y_test, y_pred):\n",
    "    print('Confusion Matrix::\\n')\n",
    "    print(pd.crosstab(y_test, y_pred))\n",
    "    print()\n",
    "    print('Classification Report::')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    FP = pd.crosstab(y_test, y_pred).iloc[0, 1]\n",
    "    FN = pd.crosstab(y_test, y_pred).iloc[1, 0]\n",
    "    Cost = (FP*10)+(FN*500)\n",
    "    return(FP, FN, Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier dictionary for reuse and collec\n",
    "clfsDict = {'Logistic Regression': LogisticRegression(solver = 'lbfgs', random_state=rand_state),\n",
    "            'SGD': SGDClassifier(random_state=rand_state),\n",
    "#            'SVM (SVC)': SVC(gamma = 0.5, random_state=rand_state), # SVM required more computing power and time to run\n",
    "            'Decision Tree': DecisionTreeClassifier(random_state=rand_state),\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=rand_state),\n",
    "            'XGB': XGBClassifier(random_state=rand_state)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 70.75 (+/- 0.16)\n",
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0   1.0\n",
      "y                 \n",
      "0.0    19926  3965\n",
      "1.0     7710  8370\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.83      0.77     23891\n",
      "         1.0       0.68      0.52      0.59     16080\n",
      "\n",
      "    accuracy                           0.71     39971\n",
      "   macro avg       0.70      0.68      0.68     39971\n",
      "weighted avg       0.70      0.71      0.70     39971\n",
      "\n",
      "\n",
      "Processing Time:: 19.567903\n",
      "\n",
      "SGD - Accuracy: 70.33 (+/- 0.33)\n",
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0   1.0\n",
      "y                 \n",
      "0.0    20925  2966\n",
      "1.0     8975  7105\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.88      0.78     23891\n",
      "         1.0       0.71      0.44      0.54     16080\n",
      "\n",
      "    accuracy                           0.70     39971\n",
      "   macro avg       0.70      0.66      0.66     39971\n",
      "weighted avg       0.70      0.70      0.68     39971\n",
      "\n",
      "\n",
      "Processing Time:: 9.758967\n",
      "\n",
      "Decision Tree - Accuracy: 84.33 (+/- 0.21)\n",
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    20746   3145\n",
      "1.0     3103  12977\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.87      0.87     23891\n",
      "         1.0       0.80      0.81      0.81     16080\n",
      "\n",
      "    accuracy                           0.84     39971\n",
      "   macro avg       0.84      0.84      0.84     39971\n",
      "weighted avg       0.84      0.84      0.84     39971\n",
      "\n",
      "\n",
      "Processing Time:: 95.556817\n",
      "\n",
      "Random Forest - Accuracy: 92.07 (+/- 0.17)\n",
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    22837   1054\n",
      "1.0     2220  13860\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.93     23891\n",
      "         1.0       0.93      0.86      0.89     16080\n",
      "\n",
      "    accuracy                           0.92     39971\n",
      "   macro avg       0.92      0.91      0.91     39971\n",
      "weighted avg       0.92      0.92      0.92     39971\n",
      "\n",
      "\n",
      "Processing Time:: 681.273889\n",
      "\n",
      "XGB - Accuracy: 92.47 (+/- 0.12)\n",
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    22568   1323\n",
      "1.0     1696  14384\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94     23891\n",
      "         1.0       0.92      0.89      0.91     16080\n",
      "\n",
      "    accuracy                           0.92     39971\n",
      "   macro avg       0.92      0.92      0.92     39971\n",
      "weighted avg       0.92      0.92      0.92     39971\n",
      "\n",
      "\n",
      "Processing Time:: 291.307310\n",
      "\n",
      "Wall Time:: 1097.466895\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "start = time()\n",
    "\n",
    "model_run_stats = []\n",
    "\n",
    "for mdl, clf in clfsDict.items():\n",
    "    start_1 = time()\n",
    "    acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_full_data = clf.predict(X_test)\n",
    "    resultsDict = {'Model': mdl\n",
    "                   , 'Accuracy': acc.mean()\n",
    "                   , 'Std': acc.std()\n",
    "                  }\n",
    "    model_run_stats.append(resultsDict)\n",
    "    print('%s - Accuracy: %0.2f (+/- %0.2f)' %(mdl, acc.mean()*100, acc.std()*100))\n",
    "    (FP, FN, Cost) = confusion_mat(y_test, y_pred_full_data)\n",
    "    results_df = results_df.append({'Classifier':mdl\n",
    "                                    , 'Features':'Full'\n",
    "                                    , 'Parameters': 'Default'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )    \n",
    "    print()\n",
    "    print('Processing Time:: %0f' %(time()-start_1))\n",
    "    print()\n",
    "    \n",
    "model_run_stats\n",
    "\n",
    "print('Wall Time:: %0f' %(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>False_Positives</th>\n",
       "      <th>False_Negatives</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>3965</td>\n",
       "      <td>7710</td>\n",
       "      <td>3894650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>2966</td>\n",
       "      <td>8975</td>\n",
       "      <td>4517160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>3145</td>\n",
       "      <td>3103</td>\n",
       "      <td>1582950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>1054</td>\n",
       "      <td>2220</td>\n",
       "      <td>1120540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>1323</td>\n",
       "      <td>1696</td>\n",
       "      <td>861230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier Features Parameters False_Positives False_Negatives  \\\n",
       "0  Logistic Regression     Full    Default            3965            7710   \n",
       "1                  SGD     Full    Default            2966            8975   \n",
       "2        Decision Tree     Full    Default            3145            3103   \n",
       "3        Random Forest     Full    Default            1054            2220   \n",
       "4                  XGB     Full    Default            1323            1696   \n",
       "\n",
       "      Cost  \n",
       "0  3894650  \n",
       "1  4517160  \n",
       "2  1582950  \n",
       "3  1120540  \n",
       "4   861230  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the combined results of the base models using all features from the original dataset\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/BaselineCostBenefitAnalysis.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Dimensionality Reduction - Feature Reduction (RFECV)\n",
    "\n",
    "In the provided dataset we have 49 variables.  It is essential to understand and determine the importance of each variable in model contribution to enhance estimator results and improve performance. This is an important concept in machine learning and centered around simplicity and optimization.  Using the sklearn.feature_selection module that examines the classes, we can determine the features having the greatest impact and contribution to the selected models. \n",
    "\n",
    "Reference: https://towardsdatascience.com/feature-selection-in-python-recursive-feature-elimination-19f1c39b8d15\n",
    "\n",
    "---\n",
    "#### Benefits of Dimensionality reduction\n",
    "- Contributes to increasing the goodness of fit metric - **R2**\n",
    "- Aligns with the principle of **Occam's razor or the law of parsimony** - simpler is better and more likely to be correct\n",
    "- Improve an estimators accuracy scores\n",
    "- Boost performance especially on high-dimensional datasets\n",
    "\n",
    "We used **Recursive Feature Elimination with Cross-Validation (RFECV)** to restrict the features used in the model.\n",
    "Recursive feature elimination (RFE) selects features by recursively considering smaller and smaller sets of features by an external estimator based on the assignment of weights against the features (e.g., the coefficients of a linear model).\n",
    "- Train the estimator on the baseline or complete set of features\n",
    "- Importance of each feature is determined by the coef_ attribute or a feature_importances_ attribute. \n",
    "- Least important features are trimmed from the original feature set.\n",
    "- The process is recursively repeated on the trimmed dataset until the optimal features desired are reached.\n",
    "\n",
    "---\n",
    "#### Parameters for RFECV: RFECV performs RFE in a cross-validation loop to identify the optimal features.\n",
    "- **estimator**: A supervised learning estimator with a fit method that provides information about feature importance.\n",
    "    - Parameter selected: **RandomForestClassifier**\n",
    "    \n",
    "    \n",
    "- **step** - If greater than or equal to 1, then step corresponds to the number of features to remove at each iteration.\n",
    "    - Parameter selected: **4**\n",
    "    \n",
    "    \n",
    "- **cv**: Determines the cross-validation splitting strategy. Integer value specifies the number of folds.\n",
    "    - Parameter selected: **3**\n",
    "    \n",
    "    \n",
    "- **scoring**: A scoring method to determine which score to maximize\n",
    "    - Parameter selected: **recall**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal count of features selected using RFECV::  12\n",
      "Optimal features selected::  Index(['x7', 'x12', 'x20', 'x23', 'x27', 'x28', 'x37', 'x38', 'x42', 'x46',\n",
      "       'x48', 'x49'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Establish the parameters for RFECV using the Random Forest estimator and run the routine\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=rand_state)\n",
    "selector = RFECV(estimator=clf, step = 4, cv=3, scoring='recall')\n",
    "\n",
    "feature_fit = selector.fit(X_train, y_train)\n",
    "\n",
    "print('Optimal count of features selected using RFECV:: ', feature_fit.n_features_)\n",
    "print('Optimal features selected:: ', X_train.columns[selector.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Features suggested for selection using RFE Cross Validation (RFECV):  18\n",
    "\n",
    "Features selected as being the most significant and having the greatest contribution to the model are:\n",
    "- x2\n",
    "- x3\n",
    "- x7\n",
    "- x8\n",
    "- x9\n",
    "- x12\n",
    "- x20\n",
    "- x23\n",
    "- x27\n",
    "- x28\n",
    "- x32\n",
    "- x37\n",
    "- x38\n",
    "- x40\n",
    "- x42\n",
    "- x46\n",
    "- x48\n",
    "- x49\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABB8AAAGDCAYAAABjpLg3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeXxcd3nv8e8zmzZLXuV9iZ14jZ0NkwUIZE/kAKGsgQIXCqS5LS2lZQmFFu5tKFyglwKBpmnhQqFAWyhLiZQ9ZE+zkUTyFjtOHC+SbEuWJWub7Xf/OGekkSxZsq2jMzP6vF8vvTRnnWcWQ85Xv+d3zDknAAAAAACAoETCLgAAAAAAAJQ2wgcAAAAAABAowgcAAAAAABAowgcAAAAAABAowgcAAAAAABAowgcAAAAAABAowgcAQEkys4vNbHvYdQAAAIDwAQBwkszsZTPrNbOjZtZiZt83s2lh15XjnHvIObd6os9rZl8ws5T/unM/n5qAc/5oomoc53Mm/OfdYWbd/uf5PTM7zcz+0cz+ZYRjzjKzfjObNZm1TgVm9lsz6xv2vbpoAs754YmqsRCZ2QfM7OGw6wAAjI3wAQBwKt7knJsm6RxJ50r6zGQ+uZlFJ/P58vybc25a3s9XQqpDkmRmsZM47GeS3izpPZKmSzpb0tOSLpf0fUlvNbOqYce8X9JvnHPtJ1/tyTnJ11hsz/vRYd+rxybxuY8R1nsOAChNhA8AgFPmnGuRdKe8EEKSZGYXmtmjZtZhZs+Z2SV522aZ2f8zs/1mdtjMfumvP+avmGbmzOwM//H3zewfzKzezLolXWpmm8xsi5l1mdk+M/uEv+8lZrbXf3yTmf1s2Hm/YWbf9B9PN7Pvmlmzf46bTybYMLM/MLOt/mu608yWDXu+PWbWaWZPm9nF/vprJP2lpHf5f+1+zl//spldkXf8wOgIf3SCM7MPmdkrku4b6/mH1XmFpCslXeece9I5l3bOHXHOfds5913/onefpLflHROVF1T8YJRzjvg5+NuuM7Nn/df+ov+aZWYLzezXZtZuZjvN7CPDXu/PzOxHZtYp6QPj/Zz88/bmj9Aws3PN7JCZxcfxWTkz+2Mz2yFph3m+bmYHzOyImT1vZuv9fYeMLsj/Dh/vuPEyszIz+5qZvWJmrWZ2q5lV+NtmmtlvzOyg/zp+Y2aL/W1flHSxpFv879Uted+bWN75B+r3a3/Er7ld0heO9/yj1PsR/33t8r8P5/nr1/rP1WFmm83szSPVMPw9zPs8bjRvlM5hM/u2/96ulXSrpIv819hxIu8tAGByET4AAE6Zf8FTJ2mnv7xI0u2SbpY0S9InJP3czGr9Q34oqVLSmZLmSvr6CTzdeyR9UVK1pIclfVfSHzrnqiWtl38hPsxPJG0ysxq/vqikd0r6sb/9B5LSks6QN4LjKkknNFzdzN4iL0R4q6RaSQ/5z5vzpLxwZpb/vP9hZuXOuTsk/a0GR1OcfQJP+wZJayVdPY7nz3eFpCecc3uOc+5/kTfSIf+YuKSGUfYf8XMws/P9c31S0gxJr5f0sn/MTyTtlbRQ0tsl/a2ZXZ53zuvkjdCYIelfNc7PyTm3X9JjygtP5H1vfuacS43zvXqLpAskrfOf5/WSVvm1vEtS2yjvQ76TPS7f//GPP0fe614k6a/9bRFJ/0/SMklLJfVKukWSnHOf9V9XbjTFR8f5fBdI2iXv3+UXx3j+IczsHZK+IO97UyNvZE2bH/j8l6S7/PP+iaR/NbMTaYt6o6RXyxuh805JVzvntkq6UdJj/muccQLnAwBMMsIHAMCp+KWZdUnaI+mApM/7698rqd45V++cyzrn7pb0lLwAYIG8oOJG59xh51zKOffACTznr5xzj/jn7ZOUkrTOzGr88z0z/ADn3G5Jz8i7oJSkyyT1OOceN7N5fj1/5pzrds4dkBeGXH+cGt7p/wU397NQ0h9K+pJzbqtzLi0vUDgn9xd159yPnHNt/iiDv5NUJulU56T4gl9z71jPP8xsSc1jnPuHkt6Q+0u6vAvKHzvnUqPsP9rn8CFJ33PO3e1/Zvucc9vMbImk10n6tHOuzzn3rKR/lvS+vHM+5pz7pXMuK+9i9kQ+px9LerfkjUDw98uFTeN5r77knGv339uUvLBrjSTzjxvr/cu9Jydy3DfzvlPP+HV/RNLH/Vq6/FqvlyT/+/Rz51yPv+2L8gKpU7HfOfct/33pO97zj+DDkr7ij6Zxzrmd/r+9CyVNk/Rl51zSOXefpN/I/3zG6cvOuQ7n3CuS7lfeKCsAQHEgfAAAnIq3+H/pvkTeBdYcf/0ySe/Iv0CXd6G5QNISSe3OucMn+ZzD/1r/NkmbJO02swds9En6Bi5G5f0VPHchukzeX/Sb82r9R3l/oR3NvzvnZuT97PfP8428c7RLMnl/KZaZ/YU/HP2Iv326Bt+vk5X/Xhz3+Ydpk/dZjMq/yHtQ0nvNm0j0LRql5cI32uewRNKLI+y/UN73oCtv3e5h9Q5/fSfyOf1M3nD8hfJGHzh5IwFy5xrrvRp4bv9i+RZJ35bUama35UbRHM9JHPened+p8+SNyqiU9HRerXf462VmleZNDrrbvNaUByXNsFObCyX/PT/u84/geJ/1Hj9Eyhn+WY+lJe9xj7wwAwBQRAgfAACnzB+58H1JX/NX7ZH0w2EX6FXOuS/722aZ2UhDpLvlXexIksxs/khPN+y5n3TOXSfvIvSXkv59lDL/Q9Il/l/yf0+D4cMeSf2S5uTVWuOcO3PsVz7EHnltB/mvucI596h58zt8Wt5w8Zn+8PAj8i54j3lNviHvhaSx3otRn3+E4+6RdH7eqIbR/EDeiIe3SXpppFElA4WM/jnskXT6CIfsl/c9qM5bt1TeXBOjvb5xf07OuQ55w/zfKS9s+olzzuWda6z3avj37JvOuVfJaxVaJa+NRBrjczrOceNxSF4rxZl5dU533iSvkvQX8kbPXOCcq5EXskijf6+6/d/H+17lHzPW8w93vM96iZnl/3dn/mc9nu/6aEb6twMAKECEDwCAifL3kq40s3Mk/UjSm8zsajOLmlm5eRNALvaHnTdI+o55E+bFzSx30fScpDPN7BwzK5fXPz4q824X+ftmNt1vB+iUlBlpX+fcQUm/ldcj/5Lz+sXl13OXpL8zsxozi5jZ6WZ2osPXb5X0GTM7069tut8DL3lD79OSDkqKmdlfy2sjyGmVdNqwi7NnJV3vvz8b5c2JcLLPP4Rz7h5Jd0v6hZm9ysxiZlbtT+r3B3m7/lzeX7P/l44z6mGMz+G7kj5oZpf77+0iM1vjvPkmHpX0Jf/7cZa8Fo1/HaXmk/mcfqzB8OTHeevH/V75219tZhf4cxd0y2tHyL2+Z+XdGaTSvIlRPzTO48bkjxT4J0lfN7O5/jkXmdnV/i7V8sKBDvMm1/z8sFO0SlqRd76D8i743+v/u/wDjRwWjPf5h/tnSZ/wv1NmZmf4rSz/7b/+T/nf50skvUnST/3jRn0Px6FV0mIzS5zAMQCAEBA+AAAmhH9h8y+S/sq/sLxO3qR+B+X9RfSTGvz/nffJ64ffJm+uiD/zz/GCpP8t7y/zO+RNKDmW90l62R92fqO8+SZG82N5Eyf+eNj690tKSNoi6bC8IfvHbUsYzjn3C3mT8/3Ur6VJ3hwFkncnkAZJL8gbbt6nocPb/8P/3WZmudEFfyXvwvCwvIv/4TWfyPOP5O2S6iX9m7xRGE2SNsp773Pn7NZgADFiKJBnxM/BOfeEpA/Km5/hiKQH5LU9SF4bzGny/jL+C0mfd978IKM50c/p15JWSmp1zj2X97pO9L2qkXcRflje59emwVE+X5eUlHcR/AMNfZ+Od9x4fVreRK6P+7Xeo8G5Qv5eUoW8EQqPy2uJyPcNSW837w4R3/TXfUTev8U2eaMxRhoZM97nH8I59x/y5p34saQueSNgZjnnkvImn6zza/2OpPc757b5hx7vPRzLfZI2S2oxs0MncBwAYJLZ4AhEAAAAAACAicfIBwAAAAAAECjCBwAAAAAAECjCBwAAAAAAECjCBwAAAAAAECjCBwAAAAAAEKhY2AWcqDlz5rjTTjst7DIAAAAAAMAwTz/99CHnXO3w9UUXPpx22ml66qmnwi4DAAAAAAAMY2a7R1pP2wUAAAAAAAgU4QMAAAAAAAgU4QMAAAAAAAgU4QMAAAAAAAgU4QMAAAAAAAhUoOGDmV1jZtvNbKeZ3TTC9plm9gsze97MnjCz9UHWAwAAAAAAJl9g4YOZRSV9W1KdpHWS3m1m64bt9peSnnXOnSXp/ZK+EVQ9AAAAAAAgHEGOfDhf0k7n3C7nXFLSTyVdN2yfdZLulSTn3DZJp5nZvABrAgAAAAAAkyzI8GGRpD15y3v9dfmek/RWSTKz8yUtk7Q4wJoAAAAAAMAkCzJ8sBHWuWHLX5Y008yelfQnkn4nKX3MicxuMLOnzOypgwcPTnylAAAAAAAgMLEAz71X0pK85cWS9ufv4JzrlPRBSTIzk/SS/6Nh+90m6TZJ2rhx4/AAAwAAAAAAFLAgw4cnJa00s+WS9km6XtJ78ncwsxmSevw5IT4s6UE/kAAAjME5p2Qmq57+jLqTafUkM95Pf1pO0szKhGZPS2hmZUKJGHdWBgAAQHgCCx+cc2kz+6ikOyVFJX3PObfZzG70t98qaa2kfzGzjKQtkj4UVD0AEKZkOquegYAgre7+zOBjPzDIX+5NZtQ9bF1PMq0e/7hc2JDJjm8wWE15TLOnlWlWVUKzqhKa7f+eVeUFFLOqyoasK49HA35HAAAAMJWYc8XVxbBx40b31FNPhV0GgBKVymQHLvi9UQS5C/3hy4MhQm9eGNDdn1ZvKj848PZLZcb/v7WxiKkyEVVVWUwViaiqEjFVJqLeT1lMVYmoKv11VWV52xIxVZVFVRH3cuXDPUm1dSfVfjSp9u5+77H/09ad1OHupNKjhBfTymLHBhXTco/LjgkvKhNBDqQDAABAsTCzp51zG4ev578WARSkTNYpmc6qP53xf+d+MupPZwfWHbNPKqNkJqv+VNb7nbdPfyqr/oy3jzfyYDAg6PZHFSQz2XHXGPVDgspcQFAWVWXcu2hfMrPSDw4GA4OKRGxguTIeVWVZXrCQFypMVouEc06dvWm1+cFE29FcODE0qGg+0qfN+zvV3p0c9f2piEfzRlHkhxZlx4QXs6eVqSoRlTfVDwAAAKYCwgcAQ2SzbuCiPXfBPuRiPu/ivj+dVTIz8j79eYHBsSFCZlh4cOw+o/1F/kSYSWWxiMpiUSViEZXFIkrEIiqPRVVVFtWMyoQWzhgcMVCZN8JgcERBLjgYXFeV8EYklMUiRX0BbWaaXhnX9Mq4VtSOvb9zTkf70wMjJ9ryR1QcTQ5Zv6P1qNq6+9WXGjmsSMQiQ0dP5IKKYeFFrlWkpjxW1O81AADAVEf4AGDA53/VpB88tntCzpW70C+LRf0AIDIQAJTFvIv6mZWRIaFAbt/ECIFBWSyisnhUiWhEZfGIyvzfiWjUWx7huFjEuGCdQGam6vK4qsvjWja7alzH9CTTeSMqkjp0tH9I60fu98tt3Wo/mlR3MjPieeJR08zKoXNUzKiIqzIRVXncC4cq4t5Ped7jikTE256/T8L7HvHdAAAAmDyEDwAkSU/vPqwfPLZbV585T2cvmeFf5A8GByNd3I8UECRiES7sMKAyEVPlrJiWzKoc1/59qcywcKJfbUcH567IrWs83KGO3pT6UplRR1ccT8Q0EETkhxMDj4/ZFvGCjeMGHdEh+5THIopFucsIAACARPgAQN5w+r/5zRbNrS7T1991DpMHIjTl8agWzqjQwhkV4z4mm3XqT2fVm8p4P8mM+vIe96b8Zf9xbyqjvrzHvcnskP2P9KbU2tl3zPEnMmloTiIaUXk8ckwwMVp4MRh+eMd4I4QSmlkV16wq77ap3IkEAAAUI64wAOjXz+3Xs3s69NW3n0XwgKITiZh3QZ8I9qI8lRkMKfqSQ8OO3lRavXnrhoYbI4chnX0pf1t2yLaxVCaiAy0ouR9vOa6ZVQnNqkx4v/31MyrjijMCAwAAhIyrDGCK60tl9JU7tuvMhTV623mLwy4HKFjxaETxaETV5fHAnsM5fxSHH0R096d1uCel9u6kDvd47SiHu5Nq78n9TumlQ91q707qaH961PPWlHt3YRkpnJidW18VHwg1asrjikRonQIAABOH8AGY4r778Eva19Grr73jbC42gJCZmcr99oyZJ3hsfzqjjlxQkR9QdKcGg4uepFo6+7S1uVNt3Un1p0eeLyNi8ts9cmFFPG+ERd7vvO3TyrgjCQAAGB3hAzCFHejq03fu36mr1s3TRafPDrscAKegLBbVvJqo5tWUj/uYnmTaDytSeWFFckhY0d6d1MuHevTMKx063J0c9Ta4iWhEM/NGTwwZZVEZHzLaItcuwvwVAABMHYQPwBT29btfUH86q89sWht2KQBCUJmIqTIR0+JxDrNwzqmrP63D/t1IhoYVqSEjLrY2d+pwd1IdvSm5UebqrIhH/aAiPrQFZFhrSP4+zF8BAEBxInwApqitzZ36tyf36AOvWa7lc6rCLgdAETAz1ZTHVVMe17LZ4/vfjUzW6Ujv0Hkrcj9DwouelHa39ehwd1Jdx5m/ojo3f0Xl6JNt5ocY0yuYvwIAgEJA+ABMQc45ffH2raqpiOtjl68MuxwAJSwasYE2i/FKprPq6PFGUYzUFpILLFo7+7RtHPNXzKhMaGZlfJT5KoZOtjmzKqFq5q8AAGDCET4AU9D92w/o4Z2H9Pk3rdP0yuBm7geAk5GIRTS3plxzT2D+it5kZuR5KwZaQbzRF6+09+jZPR063JNUKjNyP0gsYoMjKPLaPkZuB/FCjKBv9QoAQLEjfACmmFQmqy/evlUr5lTpvRcuC7scAJgQFYmoFiUqtGhGxbj2d87paH96yEiK4fNW5NZva+nU4R7vriGjzV9RHo+MHE5UJjSjMq5Y1BQxU9RMkYgpYt6oEPPXRSPKe2wyf3vE/OP8YyKR/PNo6LaBx95zRO34x5gp7/kY6QEACBbhAzDF/OSJV/TiwW790/s3MnEbgCnLzFRdHlf1Cc5f0dk70p1BUmrv7h9yW9NX2nvU3p1UV9/o81cUmhFDjPwQJBeaDDweDDFiEVNFIqaqRFSViZiqyvzfiagqy4b9zt9eFlVVIqbKRFRVZTGVxSIEIQBQoggfgCnkSG9KX7/7Bb3m9Nm6Yu3csMsBgKIS9dsxZlYlpNrxHZNMZ9XZl1Im65R1Tpmsk3NekJFxTs45ZbIa2JZ1Tll/e9Y5ZQf2G/mY3Pask7J5zzHyeeQfO/Sco5/Hf46Bcypvv8FzZp1TJuPUm8qoJ5nW/o5e9STT6k5m1NPv/R6viMkLI3KhxEghxojhRt4xfpCR21YZjzLpKAAUAMIHYAq55b4d6uhN6bPXruUvSwAwCRKxiOZMKwu7jFBls0596Yy6+71wYuB3XjgxZP0x29Nq80eT9CQz6vaPyWRH6YEZQUU8OhBY5MKJykT0mKCj6njbE1GVx6OqSERVEfceRwk1AGDcCB+AKWJ3W7e+/+jLeserFuvMhdPDLgcAMEVEIuZf9MckTUwQ45xTMpNVT39G3cn0YCgxsHy8MMNb7upLq7Wzb8j25Ch3TRlNIhpRWTwyEEZ4vyMqH7ZckYiqLOYFF+WxqCoSg/sM2S9/XSKq8lhk4BhGbxxfJuuUymSVymSVzjilslmlMk7pjPc7f30i6r3/lX6Q5H0+tPwAQSN8AKaILzdsUzwa0SeuWh12KQAAnBIzU1nMu6CfeQK3cR1LKpNVz3FGYvQlM+pLZ9SbzKgvlVVvKqO+vB9v2Vvf0ZNUc+rY/Ua7y8pYErHIYBjhBxZl8agq/LAjP7goHzMQ8QKQXCBSkXdc1kmpdFaprH+x7l+8p7NZpdJu2Pq8x9nchf6wi/7h58ntk3VKpbNKHxMa5NYfGxoMPl9uvX+eTHbUyWDHy8wbIZMLI4772w8uyvOW8/epzPuMKhMx7/1NRJSIEnBgaiN8AKaA/97VpoamFv3FlatO6NZ1AABMJfFoRNMrIppeEdxtqNOZrPrSWS+sSGbUn86oN5nNCzW8EKM/L7TIhRpDQ46Mev117d3JgfW9yaz6/cfpE2hNCZqZFI9EFIua4tGI4lFTLBJRPGZD1seiEcUj3uPyeN6+eetj/jrvsXf8wOMRzjP4nBHFIqZkZvD99+YqyQws96S8kKk3NbitvTvpbcv7fHpTmRMOPKIRGwh6cqMuyhNRVY4SdAwZnTF8n1GCECYTRyEjfABKXDbrdPPtW7Vgerk+fPGKsMsBAGBKi0UjmhaNaFpZ8P8ZnsrkAovhwcUIozaSGfWls4qaKeZf7Cf8gCAWNSX8C/qBx5HcPiNf9A8JCCKld0tX55z609ljA4xciJG3nB9ujBZ2HOzqV08yPfDZ5PY9UfGoqTzujQpKRE3xWGQgeEnkhTDxmPfZJWJ56/L38Y8riw1+jnH/847nHZPwzxPP+7wTscHlxJBlb10pfQ9wYggfgBL3y2f3qXHfEX39XWerIhENuxwAADBJchd81Qx6nHBmNtDKMjOg58hm/YDDv5NMnz+yZciyH2b0Dgs7kunBFphkJqtUOuv9znjtM729qYF2l1TGKTlk++BxQcgPM3KBx5CAIjYsKBkegviBR3k8qip/gthpZTFvotiyqPc44a3LLTOnR2EgfABKWG8yo6/csV1nL56u685eFHY5AAAAGKdIxAZaLGZN4Nwm4+WcG5iTYzCccH44MbiczF9OD87VkQszhgQhA4+95f4hy1kl027Icnd/Wsm8OUa8EMUpmfZG8Iw3IIlGTJWJ6EBIkbsd72Bw4d3VZuRtsSHHTiuLqTxOmHEyCB+AEnbbg7vU0tmnb73nXGbJBgAAwLiZDbbTVE5+9jEuyXTWv/2uNzns0f7c3W7SOtqfydvm3w3HX85ta+/uGTi2uz+t/nHe8SZiygsron5gMXR52sC66ECoMc2/5e+0YSFHZSI6JcIMwgegRLV29unWB17Upg3z9erTZoVdDgAAADChErGIErHEhN31JuXfwvdoMq2e/rSO5t3C1wswvOCiJ5nb5t0JJ7dtX0dvXvjhzeExHuaHGfkjLCoTUV2wYrb+/MpVE/LaCgHhA1CivnbndmWyTjddszbsUgAAAICCF49GNL0youmVE3PHm0zWDQkuciMsvBEamcEAIy/EyN/WfxKTjhYywgegBDXtO6KfPbNXN1y8QktnV4ZdDgAAADDlRCOmmvK4asqDu31vMeFGsECJcc7p5tu3aGZlQn906RlhlwMAAAAAhA9Aqbl7S6se39Wuj1+xUtMrSFkBAAAAhI/wASghyXRWX2rYpjPmTtO7z18adjkAAAAAIInwASgpP3x8t1461K3PXrtWsSj/vAEAAAAUBq5OgBLR0ZPUN+/doYtXztElq2rDLgcAAAAABhA+ACXiG/fuUFdfSp+7dp3MLOxyAAAAAGAA4QNQAl48eFQ/fGy3rj9/qVbPrw67HAAAAAAYgvABKAFfqt+m8nhUH79iVdilAAAAAMAxCB+AIvfozkO6Z2ur/ujS01VbXRZ2OQAAAABwDMIHoIhlsk43375Vi2ZU6A9euzzscgAAAABgRIQPQBH7+dN7taW5UzfVrVF5PBp2OQAAAAAwIsIHoEh196f11bu269ylM/TGsxaEXQ4AAAAAjIrwAShS//jAizrY1a+/eiO31gQAAABQ2AgfgCK0v6NXtz20S28+e6HOWzoz7HIAAAAA4LgIH4Ai9NU7tyvrpE9dszrsUgAAAABgTIQPQJF5bk+HfvG7ffrw65Zr8czKsMsBAAAAgDERPgBFxDmnm2/fojnTEvqfl5wedjkAAAAAMC6ED0ARaWhq0ZMvH9ZfXLVa1eXxsMsBAAAAgHEhfACKRH86oy81bNWa+dV658YlYZcDAAAAAONG+AAUiR88+rL2tPfqs9euVTTCrTUBAAAAFA/CB6AItB3t17fu3alLV9fq4pW1YZcDAAAAACeE8AEoAn9/zw71pDL67LVrwy4FAAAAAE4Y4QNQ4Ha0dunHT7yi379gqc6YWx12OQAAAABwwggfgAL3t/VbVZmI6s+uWBV2KQAAAABwUggfgAL24AsHdf/2g/rTy1ZqVlUi7HIAAAAA4KQQPgAFKp3J6ubbt2jprEq9/zXLwi4HAAAAAE4a4QNQoP79qb16ofWoPlO3RmWxaNjlAAAAAMBJI3wAClBXX0r/9+7tOv+0Wbpm/fywywEAAACAUxILuwAAx/rOb1/UoaNJfe8Da2VmYZcDAAAAAKck0JEPZnaNmW03s51mdtMI26eb2X+Z2XNmttnMPhhkPUAx2NPeo+8+/JLeeu4inbV4RtjlAAAAAMApCyx8MLOopG9LqpO0TtK7zWzdsN3+WNIW59zZki6R9HdmxpT+mNK+cud2RUz6xNWrwy4FAAAAACZEkCMfzpe00zm3yzmXlPRTSdcN28dJqjZvXPk0Se2S0gHWBBS0p3cf1n89t183XLxCC2dUhF0OAAAAAEyIIMOHRZL25C3v9dflu0XSWkn7JTVK+phzLhtgTUDBcs7pb36zRXOry/SHbzg97HIAAAAAYMIEGT6MNEueG7Z8taRnJS2UdI6kW8ys5pgTmd1gZk+Z2VMHDx6c+EqBAvBfzzfr2T0d+sTVq1VVxlywAAAAAEpHkOHDXklL8pYXyxvhkO+Dkv7TeXZKeknSmuEncs7d5pzb6JzbWFtbG1jBQFj6Uhn9n4ZtWregRm87b3HY5QAAAADAhAoyfHhS0kozW+5PInm9pF8P2+cVSZdLkpnNk7Ra0q4AawIK0ncffkn7Onr1uTeuVTTCrTUBAAAAlJbAxnY759Jm9lFJd0qKSvqec26zmd3ob79V0t9I+r6ZNcpr0/i0c+5QUDUBhehgV7++c/9OXblunl5z+pywywEAAACACRdoY7lzrl5S/bB1t+Y93i/pqiBrAArd/737BfWns/pM3TEdRwAAAABQEoJsuwAwhm0tnfq3J1/R+y5aphW108IuBwAAAAACQfgAhMQ5p3FVuLEAACAASURBVC/evlXV5XF97PKVYZcDAAAAAIEhfABC8tvtB/XQjkP62OUrNaMyEXY5AAAAABAYwgcgBKlMVjffvkXL51TpvRcuC7scAAAAAAgU4QMQgp888YpePNitv9y0VokY/wwBAAAAlDaueoBJdqQ3pa/f/YIuWjFbV6ydG3Y5AAAAABA4wgdgkn37/p3q6E3ps9eulZmFXQ4AAAAABI7wAZhEu9u69f1HXtbbz1us9Yumh10OAAAAAEwKwgdgEn25YZtiUdMnrl4ddikAAAAAMGkIH4BJ8sRL7WpoatGNbzhd82rKwy4HAAAAACYN4QMwCbJZp5tv36L5NeX6yMUrwi4HAAAAACYV4QMwCX757D49v/eIPnXNalUkomGXAwAAAACTivABCFhvMqOv3LFdZy2errecsyjscgAAAABg0hE+AAH7p4d2qaWzT5+7dp0iEW6tCQAAAGDqIXwAAtTa2ad/+O2Lqls/X+cvnxV2OQAAAAAQCsIHIEBfu3O7Mlmnm+rWhF0KAAAAAISG8AEISNO+I/rZM3v1gdeepmWzq8IuBwAAAABCQ/gABMA5py/evlUzKuL640vPCLscAAAAAAgV4QMQgLu3tOqxXW36+JWrNL0iHnY5AAAAABAqwgdggiXTWX2pYZvOmDtN7zl/adjlAAAAAEDoCB+ACfajx3frpUPd+uymtYpF+ScGAAAAAFwZAROooyepb9y7QxevnKNLVteGXQ4AAAAAFATCB2ACfePeHerqS+mz166VmYVdDgAAAAAUBMIHYILsOnhUP3xst9716qVaM78m7HIAAAAAoGAQPgAT5EsN21QWi+jPr1wVdikAAAAAUFAIH4AJ8OiLh3T3llb90aVnqLa6LOxyAAAAAKCgED4ApyiTdbr5N1u1aEaFPvS65WGXAwAAAAAFh/ABOEU/f2avtjR36tN1a1Qej4ZdDgAAAAAUHMIH4BR096f1tTu369ylM/SmsxaEXQ4AAAAAFCTCB+AU/OMDL+pAV78+d+06bq0JAAAAAKMgfABO0v6OXt320C696eyFetWymWGXAwAAAAAFi/ABOElfu3O7sk761NWrwy4FAAAAAAoa4QNwEp7f26H//N0+feh1y7VkVmXY5QAAAABAQSN8AE6Qc05/85stmjMtoT+65PSwywEAAACAgkf4AJygO5pa9OTLh/XnV65WdXk87HIAAAAAoOARPgAnoD+d0Zcatmn1vGq9c+PisMsBAAAAgKJA+ACcgB88+rJeae/RZ69dq1iUfz4AAAAAMB5cPQHj1Ha0X9+6d6cuXV2r16+qDbscAAAAACgahA/AOH3rvp3qSWX0l5vWhl0KAAAAABQVwgdgHJLprH7+zF69+eyFWjmvOuxyAAAAAKCoED4A4/DIi4fU1ZfWm85eEHYpAAAAAFB0CB+AcWhobFZ1WUyvPWNO2KUAAAAAQNEhfADGkMpkddeWVl2xbp7KYtGwywEAAACAokP4AIzh8V1t6uhJqW79/LBLAQAAAICiRPgAjKG+sUVViSi31wQAAACAk0T4ABxHOpPVXZtbdNnaeSqP03IBAAAAACeD8AE4jidebldbd1KbaLkAAAAAgJNG+AAcR0NjiyriUV2yem7YpQAAAABA0SJ8AEaRyTrdsblFl66pVUWClgsAAAAAOFmED8Aont59WAe7+lW3fkHYpQAAAABAUSN8AEZR39isslhEl66h5QIAAAAATgXhAzCCbNbpjqYWvWFVraaVxcIuBwAAAACKGuEDMILf7elQS2efNm2g5QIAAAAAThXhAzCChsZmJaIRXbaWlgsAAAAAOFWED8Awzjk1NLXo4pVzVFMeD7scAAAAACh6hA/AMM/vPaJ9Hb2qo+UCAAAAACZEoOGDmV1jZtvNbKeZ3TTC9k+a2bP+T5OZZcxsVpA1AWOpb2pWLGK6cu28sEsBAAAAgJIQWPhgZlFJ35ZUJ2mdpHeb2br8fZxzX3XOneOcO0fSZyQ94JxrD6omYCzOOTU0tui1Z8zR9EpaLgAAAABgIgQ58uF8STudc7ucc0lJP5V03XH2f7eknwRYDzCmzfs79Up7jzZtmB92KQAAAABQMoIMHxZJ2pO3vNdfdwwzq5R0jaSfB1gPMKb6xmZFI6Yr1xE+AAAAAMBECTJ8sBHWuVH2fZOkR0ZruTCzG8zsKTN76uDBgxNWIJDPOaf6xmZdtGK2ZlUlwi4HAAAAAEpGkOHDXklL8pYXS9o/yr7X6zgtF86525xzG51zG2trayewRGDQtpYuvdzWo03c5QIAAAAAJlSQ4cOTklaa2XIzS8gLGH49fCczmy7pDZJ+FWAtwJgaGpsVMemqM7nLBQAAAABMpFhQJ3bOpc3so5LulBSV9D3n3GYzu9Hffqu/6+9Juss51x1ULcB41De16ILlszVnWlnYpQAAAABASQksfJAk51y9pPph624dtvx9Sd8Psg5gLDtau7TzwFH9j4uWhV0KAAAAAJScINsugKJR39giM+nqM7nLBQAAAABMNMIHQFJDU7NevWyW5taUh10KAAAAAJQcwgdMeS8ePKptLV2q28CoBwAAAAAIAuEDprw7mlokSdesJ3wAAAAAgCAQPmDKq29s1nlLZ2jB9IqwSwEAAACAknTcu12YWZckN9ImSc45VxNIVcAk2d3Wrc37O/W5a9eGXQoAAAAAlKzjhg/OuerJKgQIQwMtFwAAAAAQuLFGPsw63nbnXPvElgNMrobGZp29eLoWz6wMuxQAAAAAKFnHDR8kPS2v7cJG2OYkrZjwioBJsvdwj57be0Q31a0JuxQAAAAAKGljtV0sn6xCgMmWu8tFHS0XAAAAABCosUY+DDCzmZJWSirPrXPOPRhEUcBkqG9s1pkLa7RsdlXYpQAAAABASRtX+GBmH5b0MUmLJT0r6UJJj0m6LLjSgOA0H+nVM6906JNXrw67FAAAAAAoeZFx7vcxSa+WtNs5d6mkcyUdDKwqIGC0XAAAAADA5Blv+NDnnOuTJDMrc85tk8SfjFG0GhpbtGZ+tVbUTgu7FAAAAAAoeeMNH/aa2QxJv5R0t5n9StL+4MoCgnOgs09P7m5X3foFYZcCAAAAAFPCuOZ8cM79nv/wC2Z2v6Tpku4IrCogQHdubpFz0qYNtFwAAAAAwGQY18gHM7vQzKolyTn3gKT75c37ABSd+sYWnTF3mlbOqw67FAAAAACYEsbbdvEPko7mLXf764Cicuhov/77pTZtYqJJAAAAAJg04w0fzDnncgvOuazG2bIBFJK7Nrcq66S6Dcz3AAAAAACTZbzhwy4z+1Mzi/s/H5O0K8jCgCA0NDVr+ZwqrZlPywUAAAAATJbxhg83SnqNpH2S9kq6QNINQRUFBOFwd1KPvtimuvXzZWZhlwMAAAAAU8Z473ZxQNL1AdcCBOruLa3KZJ020XIBAAAAAJNqvHe7WGVm95pZk798lpl9LtjSgIlV39SsJbMqdObCmrBLAQAAAIApZbxtF/8k6TOSUpLknHtejIRAETnSk9IjOw9p0/oFtFwAAAAAwCQbb/hQ6Zx7Yti69EQXAwTlnq2tSmUcd7kAAAAAgBCMN3w4ZGanS3KSZGZvl9QcWFXABGtoatbC6eU6e/H0sEsBAAAAgClnXBNOSvpjSbdJWmNm+yS9JOn3A6sKmECdfSk9+MIhve+iZbRcAAAAAEAIxnu3i12SrjCzKnmjJXolvUvS7gBrAybEfVsPKJnJatOG+WGXAgAAAABT0nHbLsysxsw+Y2a3mNmVknok/Q9JOyW9czIKBE5VfWOz5tWU6dwlM8MuBQAAAACmpLFGPvxQ0mFJj0n6iKRPSUpIeotz7tmAawNO2dH+tH77wkG95/ylikRouQAAAACAMIwVPqxwzm2QJDP7Z0mHJC11znUFXhkwAe7fdkDJdFZ162m5AAAAAICwjHW3i1TugXMuI+klggcUk4amZs2ZVqaNp80KuxQAAAAAmLLGGvlwtpl1+o9NUoW/bJKcc64m0OqAU9CTTOv+bQf19lctVpSWCwAAAAAIzXHDB+dcdLIKASbaA9sPqjeVUR13uQAAAACAUI3VdgEUrfqmFs2uSuh8Wi4AAAAAIFSEDyhJfamM7tvaqqvOnK9YlK85AAAAAISJqzKUpAdfOKjuZEabaLkAAAAAgNARPqAkNTS1aEZlXBeumB12KQAAAAAw5RE+oOT0pzO6Z0urrlo3T3FaLgAAAAAgdFyZoeQ8svOQuvrTqtuwIOxSAAAAAAAifEAJqm9sUXV5TK89fU7YpQAAAAAARPiAEpNMZ3XX5hZduW6eEjG+3gAAAABQCLg6Q0l5bFebOvvS2rSelgsAAAAAKBSEDygpDY3NmlYW0+tW0nIBAAAAAIWC8AElI53J6s7NLbp87VyVx6NhlwMAAAAA8BE+oGT890vtOtyTUh0tFwAAAABQUAgfUDLqG5tVmYjqktW1YZcCAAAAAMhD+ICSkMk63bm5RZeuoeUCAAAAAAoN4QNKwpMvt+vQ0SR3uQAAAACAAkT4gJLQ0Nis8niElgsAAAAAKECEDyh62axTQ1OLLlk1V1VlsbDLAQAAAAAMQ/iAovfMK4d1oKtfdRvmh10KAAAAAGAEhA8oevWNLUrEIrpszdywSwEAAAAAjIDwAUXNa7lo1utX1qq6PB52OQAAAACAERA+oKg9t7dDzUf6tImWCwAAAAAoWIQPKGoNTS2KR02Xr50XdikAAAAAgFEEGj6Y2TVmtt3MdprZTaPsc4mZPWtmm83sgSDrQWlxzqm+sVmvO2OOplfQcgEAAAAAhSqw8MHMopK+LalO0jpJ7zazdcP2mSHpO5Le7Jw7U9I7gqoHpadpX6f2Hu5V3YYFYZcCAAAAADiOIEc+nC9pp3Nul3MuKemnkq4bts97JP2nc+4VSXLOHQiwHpSY+qZmxSKmq9bRcgEAAAAAhSzI8GGRpD15y3v9dflWSZppZr81s6fN7P0B1oMSkmu5uOj02ZpRmQi7HAAAAADAccQCPLeNsM6N8PyvknS5pApJj5nZ4865F4acyOwGSTdI0tKlSwMoFcVmS3Ondrf16MY3nB52KQAAAACAMQQ58mGvpCV5y4sl7R9hnzucc93OuUOSHpR09vATOeduc85tdM5trK2tDaxgFI+GxhZFTLRcAAAAAEARCDJ8eFLSSjNbbmYJSddL+vWwfX4l6WIzi5lZpaQLJG0NsCaUgFzLxYUrZmv2tLKwywEAAAAAjCGwtgvnXNrMPirpTklRSd9zzm02sxv97bc657aa2R2SnpeUlfTPzrmmoGpCaXih9ah2HerWB1+3POxSAAAAAADjEOScD3LO1UuqH7bu1mHLX5X01SDrQGmpb2yWmXT1mbRcAAAAAEAxCLLtAghEQ1OzXn3aLM2tLg+7FAAAAADAOBA+oKjsPNClF1qPatP6+WGXAgAAAAAYJ8IHFJWGxhZJ0jXrF4RcCQAAAABgvAgfUFTqm1r0qmUzNX86LRcAAAAAUCwIH1A0XjrUra3Nndq0gVEPAAAAAFBMCB9QNBqamiVJ1zDfAwAAAAAUFcIHFI2Gxhads2SGFs2oCLsUAAAAAMAJIHxAUdjT3qPGfUe0aQOjHgAAAACg2BA+oCjkWi7quMsFAAAAABQdwgcUhfrGFm1YNF1LZlWGXQoAAAAA4AQRPqDg7evo1bN7OlRHywUAAAAAFCXCBxS8O5paJNFyAQAAAADFivABBa+hsVlrF9Ro+ZyqsEsBAAAAAJwEwgcUtJYjfXpq92FtWk/LBQAAAAAUK8IHFLQ7N/stFxtouQAAAACAYkX4gIJW39isVfOm6Yy508IuBQAAAABwkggfULAOdvXriZfbmWgSAAAAAIoc4QMK1p2bW+SctImWCwAAAAAoaoQPKFgNTc1aUVulVfNouQAAAACAYkb4gILUdrRfj+9q16b1C2RmYZcDAAAAADgFhA8oSHdvaVUm61S3gVtsAgAAAECxI3xAQapvatGy2ZVat6Am7FIAAAAAAKeI8AEFp6MnqUd3HlIdLRcAAAAAUBIIH1Bw7t7SqnTWaRMtFwAAAABQEggfUHAamlq0aEaFNiyaHnYpAAAAAIAJQPiAgtLZl9JDOw5q04b5tFwAAAAAQIkgfEBBuWdLq1IZp7oNC8IuBQAAAAAwQQgfUFDqG1u0YHq5zlk8I+xSAAAAAAAThPABBaOrL6UHdxzUNevnKxKh5QIAAAAASgXhAwrGfdsOKJnOahMtFwAAAABQUggfUDAaGls0t7pMr1o6M+xSAAAAAAATiPABBaG7P637tx+g5QIAAAAAShDhAwrCb7cfVH86q7r1tFwAAAAAQKkhfEBBqG9q1uyqhM5fPivsUgAAAAAAE4zwAaHrTWZ0/7YDunr9fEVpuQAAAACAkkP4gNA98MJB9SQz2kTLBQAAAACUJMIHhK6hqVkzK+O6YAUtFwAAAABQiggfEKq+VEb3bj2gq9bNVzzK1xEAAAAAShFXewjVwzsO6Wh/WnUb5oddCgAAAAAgIIQPCFV9U7NqymN6zelzwi4FAAAAABAQwgeEJpnO6u4trbpy3XwlYnwVAQAAAKBUccWH0Dzy4iF19aV17Vm0XAAAAABAKSN8QGgaGptVXRbTa8+g5QIAAAAAShnhA0KRymR115ZWXbFunspi0bDLAQAAAAAEiPABoXh8V5s6elKqW0/LBQAAAACUOsIHhKK+sUVViahev6o27FIAAAAAAAEjfMCkS2eyumtziy5bO0/lcVouAAAAAKDUET5g0j3xcrvaupPaRMsFAAAAAEwJhA+YdA2NLaqIR3XJ6rlhlwIAAAAAmASED5hUmazTHZtbdOmaWlUkaLkAAAAAgKmA8AGT6undh3Wwq1916xeEXQoAAAAAYJIQPmBS1Tc2qywW0aVraLkAAAAAgKmC8AGTJpt1uqOpRW9YVatpZbGwywEAAAAATBLCB0ya3+3pUEtnnzZtoOUCAAAAAKYSwgdMmobGZiWiEV22lpYLAAAAAJhKCB8wKZxzamhq0cUr56imPB52OQAAAACASRRo+GBm15jZdjPbaWY3jbD9EjM7YmbP+j9/HWQ9CM/ze49oX0ev6mi5AAAAAIApJ7BZ/8wsKunbkq6UtFfSk2b2a+fclmG7PuSce2NQdaAw1Dc1KxYxXbl2XtilAAAAAAAmWZAjH86XtNM5t8s5l5T0U0nXBfh8KFDOOTU0tui1Z8zR9EpaLgAAAABgqgkyfFgkaU/e8l5/3XAXmdlzZtZgZmcGWA9Csnl/p15p79GmDfPDLgUAAAAAEILA2i4k2Qjr3LDlZyQtc84dNbNNkn4paeUxJzK7QdINkrR06dKJrhMBq29sVjRiunId4QMAAAAATEVBjnzYK2lJ3vJiSfvzd3DOdTrnjvqP6yXFzWzO8BM5525zzm10zm2sra0NsGRMNOec6hubddGK2ZpVlQi7HAAAAABACIIMH56UtNLMlptZQtL1kn6dv4OZzTcz8x+f79fTFmBNmGTbWrr0cluP6mi5AAAAAIApK7C2C+dc2sw+KulOSVFJ33PObTazG/3tt0p6u6T/aWZpSb2SrnfODW/NQBFraGxWxKSraLkAAAAAgCkryDkfcq0U9cPW3Zr3+BZJtwRZA8JV39Si85fPUm11WdilAAAAAABCEmTbBaa4Ha1d2nngqDZtWBB2KQAAAACAEBE+IDD1jS0yk64+k5YLAAAAAJjKCB8QmIamZm1cNlPzasrDLgUAAAAAECLCBwTixYNHta2lS3XrabkAAAAAgKmO8AGBuKOpRZJ0zXpaLgAAAABgqiN8QCDqG5t17tIZWjijIuxSAAAAAAAhI3zAhNvd1q3N+zu1iZYLAAAAAIAIHxCABlouAAAAAAB5CB8w4Roam3XW4ulaMqsy7FIAAAAAAAWA8AETau/hHj239wh3uQAAAAAADCB8wITK3eWijpYLAAAAAICP8AETqr6xWesW1Oi0OVVhlwIAAAAAKBCED5gwzUd69cwrHdq0gVEPAAAAAIBBhA+YMLmWi00bmO8BAAAAADCI8AETpqGxRWvmV2tF7bSwSwEAAAAAFBDCB0yIA519enJ3O3e5AAAAAAAcg/ABE+LOzS1yTsz3AAAAAAA4RizsAlC8nHPa3tqle7ce0L8+vltnzJ2mlfOqwy4LAAAAAFBgCB9wQvrTGT2+q133bm3VvVsPaF9HryTprMXT9cmrV4dcHQAAAACgEBE+YEwHu/p1/7YDundbqx7acUg9yYwq4lG9buUc/cllZ+iyNXM1t6Y87DIBAAAAAAWK8AHHcM5pa3OX7tvWqnu2HtBzezvknLRgerneet4iXb5mni46fbbK49GwSwUAAAAAFAHCB0iS+lIZPbarTfdtPaD7tg22U5y9ZIb+/IpVumztXK1bUCMzC7lSAAAAAECxIXyYwg509XntFFsP6OGdg+0UF6+co49dvlKXrKnV3GraKQAAAAAAp4bwYQpxzmlLc6fu3XpA9247oOf2dEiSFk4v19vOW6zL187VhStopwAAAAAATCzChxLXl8rosRfbdM/WVt237YCaj/TJTDp78Qx94qpVumzNPK1dUE07BQAAAAAgMIQPJehAZ5/u23ZA92w9oEd2HlJvKqPKhNdO8fErV+nS1XNVW10WdpkAAAAAgCmC8KEEOOe0eX+unaJVz+89IklaNKNC79i4WJevnacLV8xSWYx2CgAAAADA5CN8KFJ9qYweffGQ7tl6QPdtPaCWTq+d4twlM/TJq1fr8rVztXoe7RQAAAAAgPARPhSRVr+d4t6trXp45yH1pbKqSkT1+lW1umzNXF26Zq7mTKOdAgAAAABQWAgfCphzTk37OnXvtlbdu/WAGvd57RSLZ1bo+lcv1WVr5uoC2ikAAAAAAAWO8KHA9Cbz2im2taq1s19m0nlLZ+pT16zW5WvmadW8abRTAAAAAACKBuFDAWg5MthO8ciLXjvFtLKYXr9qji5fM0+XrK7VbNopAAAAAABFivAhBNmsU9P+IwN3p2ja1ylJWjLLa6e4Yu08nb98lhKxSMiVAgAAAABw6ggfJklvMqOHdx7Sff78DQe6+hXx2yk+fc0aXbF2rs6YSzsFAAAAAKD0ED4ELJN1+sMfPqWHdhxSfzqr6rKYXr+qVpevnatLVs/VrKpE2CUCAAAAABAowoeARSP2/9u7/2DL6zmO48+X3VJbazaz8mMXq50U7aRNqAxDiCG7GT9CyBQzYlKG0DQM41dk/CjjR8hmRNiKlWFbRQwp2tptkzSjZFkq+TUxiLc/zieu6/7Yc+6e/e49PR8zd+73fH++znnPveec9/l8v4d5O8/lxY/rnU7xmCWeTiFJkiRJumex+bAdnPGi5V1HkCRJkiSpM34EL0mSJEmShsrmgyRJkiRJGiqbD5IkSZIkaahsPkiSJEmSpKGy+SBJkiRJkobK5oMkSZIkSRoqmw+SJEmSJGmobD5IkiRJkqShsvkgSZIkSZKGyuaDJEmSJEkaKpsPkiRJkiRpqGw+SJIkSZKkobL5IEmSJEmShipV1XWGviS5DfhF1zk0oYXA7V2H0IxZx9FgHUeDdRwN1nF0WMvRYB1Hg3XccT20qu43fuasaz5ox5Xkx1V1UNc5NDPWcTRYx9FgHUeDdRwd1nI0WMfRYB1nH0+7kCRJkiRJQ2XzQZIkSZIkDZXNB21LZ3UdQNuEdRwN1nE0WMfRYB1Hh7UcDdZxNFjHWcZrPkiSJEmSpKFy5IMkSZIkSRoqmw+akSQPTvLtJNcnuS7JiV1n0uCSzElydZKLus6iwSVZkGR1kp+2v81Dus6k/iV5Xfu/uinJF5Ls0nUmTS/J2UluTbJpzLz7JlmX5Mb2e48uM2p6k9Tx9PZ/dWOSC5Ms6DKjpjdRHccse0OSSrKwi2zqz2S1THJCkhva8+X7usqnrWPzQTN1F/D6qnoEcDDwmiSP7DiTBncicH3XITRjHwa+WVX7Ao/Cms46SRYBrwUOqqplwBzghd2m0lZaBTxj3Lw3A5dU1d7AJe22dmyr+P86rgOWVdX+wM+AU7Z3KPVtFf9fR5I8GHgacMv2DqSBrWJcLZM8GVgJ7F9V+wHv7yCX+mDzQTNSVVuqan2b/jO9NzmLuk2lQSRZDDwL+FTXWTS4JPcBngh8GqCq/l5Vf+g2lQY0F9g1yVxgHvDrjvNoK1TVd4E7xs1eCZzTps8BjtyuodS3iepYVRdX1V3t5g+Bxds9mPoyyd8jwAeBNwJe/G6WmKSWxwOnVdXf2jq3bvdg6ovNB20zSZYAy4Eruk2iAX2I3hPxv7oOohnZC7gN+Ew7heZTSXbrOpT6U1W/ovcJzi3AFuCPVXVxt6k0A/evqi3Qa9oDe3acRzN3LPCNrkOof0lWAL+qqg1dZ9GMPRx4QpIrklyW5DFdB9LUbD5om0iyO3A+cFJV/anrPOpPkiOAW6vqqq6zaMbmAgcCH6uq5cCdOMR71mnXBFgJPAx4ELBbkpd0m0oSQJJT6Z12em7XWdSfJPOAU4G3dp1F28RcYA96p36fDHwpSbqNpKnYfNCMJdmJXuPh3Kq6oOs8GsjjgRVJbgbOAw5L8rluI2lAm4HNVXX3CKTV9JoRml2eCtxUVbdV1T+AC4BDO86kwf02yQMB2m+HBs9SSY4BjgCOLr+vfjZaSq+pu6G95lkMrE/ygE5TaVCbgQuq50p6o3e9gOgOzOaDZqR1Fz8NXF9VH+g6jwZTVadU1eKqWkLvonaXVpWfss5CVfUb4JdJ9mmzngL8pMNIGswtwMFJ5rX/s0/BC4fOZmuAY9r0McBXO8yiASV5BvAmYEVV/aXrPOpfVV1bVXtW1ZL2mmczcGB77tTs8xXgMIAkDwd2Bm7vNJGmZPNBM/V44KX0Pim/pv08s+tQ0j3cCcC5STYCBwDv7jiP+tRGrqwG1gPX0nu+PqvTUNoqSb4AXA7seK+cvwAABF9JREFUk2RzkuOA04CnJbmR3hX2T+syo6Y3SR0/AswH1rXXOx/vNKSmNUkdNQtNUsuzgb3a12+eBxzjiKQdW6yPJEmSJEkaJkc+SJIkSZKkobL5IEmSJEmShsrmgyRJkiRJGiqbD5IkSZIkaahsPkiSJEmSpKGy+SBJ0ohJ8s8xX398TZIlA+zjyCSP3Pbpto0kb0vyhgG2W5Dk1dvreJIkqcfmgyRJo+evVXXAmJ+bB9jHkUBfzYckcwc4zva2AOi7+SBJkmbG5oMkSfcASR6d5LIkVyVZm+SBbf4rk/woyYYk5yeZl+RQYAVwehs5sTTJd5Ic1LZZmOTmNv3yJF9O8jXg4iS7JTm77fPqJCvbevslubLtb2OSvcflm5NkVZJNSa5N8ro2f2mSb7bc30uy7wT3bcJ1ktw/yYXtvm1o9+s0YGnLcXpb7+SWd2OSt4/Z76lJbkjyLWCfbVwSSZLuUWbDJxSSJKk/uya5pk3fBLwAOBNYWVW3JTkKeBdwLHBBVX0SIMk7geOq6swka4CLqmp1WzbV8Q4B9q+qO5K8G7i0qo5NsgC4sr15fxXw4ao6N8nOwJxx+zgAWFRVy9rxFrT5ZwGvqqobkzwO+Chw2LhtJ1vnDOCyqnpOkjnA7sCbgWVVdUA7zuHA3sBjgQBrkjwRuBN4IbCc3uul9cBVUz0IkiRpcjYfJEkaPX+9+801QJJlwDJgXWsizAG2tMXLWtNhAb0352sHON66qrqjTR8OrBhzfYRdgIcAlwOnJllMr+Fx47h9/BzYK8mZwNfpjaLYHTgU+PKY5se9x240zTqHAS8DqKp/An9Msse44x7efq5ut3en14yYD1xYVX9px1mzlY+FJEmagM0HSZJGX4DrquqQCZatAo6sqg1JXg48aZJ93MV/T9fcZdyyO8cd67lVdcO4da5PcgXwLGBtkldU1aV3L6yq3yd5FPB04DX0RmucBPxhbCNlAvfainWmEuA9VfWJ/5mZnATUgPuUJEnjeM0HSZJG3w3A/ZIcApBkpyT7tWXzgS1JdgKOHrPNn9uyu90MPLpNP2+KY60FTkgbhpBkefu9F/DzqjoDWAPsP3ajJAuBe1XV+cBbgAOr6k/ATUme39ZJa1D8xzTrXAIc3+bPSXKfCe7XWuDYNoKCJIuS7Al8F3hOkl2TzAeePcV9liRJ07D5IEnSiKuqv9NrGLw3yQbgGnqnKkDvjf4VwDrgp2M2Ow84uV00cinwfuD4JD8AFk5xuHcAOwEbk2xqtwGOAja1a1HsC3x23HaLgO+05auAU9r8o4HjWu7rgJUTHHOydU4EnpzkWnrXa9ivqn4HfL9d2PL0qroY+DxweVtvNTC/qtYDX2yP1fnA96a4z5IkaRqpckShJEmSJEkaHkc+SJIkSZKkobL5IEmSJEmShsrmgyRJkiRJGiqbD5IkSZIkaahsPkiSJEmSpKGy+SBJkiRJkobK5oMkSZIkSRoqmw+SJEmSJGmo/g1sKo+tQhFkiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot features selected against the model score\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.title('Recursive Feature CV score versus Feature count')\n",
    "plt.xlabel(\"Features selected\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training and test sets using just the reduced features \n",
    "# identified from the RFECV exercise conducted above\n",
    "X_train_reduced_features = X_train[X_train.columns[selector.support_]]\n",
    "X_test_reduced_features = X_test[X_test.columns[selector.support_]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x12</th>\n",
       "      <th>x20</th>\n",
       "      <th>x23</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x32</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x40</th>\n",
       "      <th>x42</th>\n",
       "      <th>x46</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148087</th>\n",
       "      <td>0.379438</td>\n",
       "      <td>0.411585</td>\n",
       "      <td>0.446122</td>\n",
       "      <td>0.787073</td>\n",
       "      <td>0.500812</td>\n",
       "      <td>0.412573</td>\n",
       "      <td>0.515263</td>\n",
       "      <td>0.413684</td>\n",
       "      <td>0.623665</td>\n",
       "      <td>0.394348</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.473806</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>0.501370</td>\n",
       "      <td>0.48113</td>\n",
       "      <td>0.623751</td>\n",
       "      <td>0.607118</td>\n",
       "      <td>0.634293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104909</th>\n",
       "      <td>0.300386</td>\n",
       "      <td>0.486774</td>\n",
       "      <td>0.561974</td>\n",
       "      <td>0.689705</td>\n",
       "      <td>0.332694</td>\n",
       "      <td>0.687903</td>\n",
       "      <td>0.447419</td>\n",
       "      <td>0.455964</td>\n",
       "      <td>0.407315</td>\n",
       "      <td>0.481023</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.462753</td>\n",
       "      <td>0.369177</td>\n",
       "      <td>0.421769</td>\n",
       "      <td>0.51585</td>\n",
       "      <td>0.693056</td>\n",
       "      <td>0.672425</td>\n",
       "      <td>0.618994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x2        x3        x7        x8        x9       x12       x20  \\\n",
       "148087  0.379438  0.411585  0.446122  0.787073  0.500812  0.412573  0.515263   \n",
       "104909  0.300386  0.486774  0.561974  0.689705  0.332694  0.687903  0.447419   \n",
       "\n",
       "             x23       x27       x28  x32       x37       x38       x40  \\\n",
       "148087  0.413684  0.623665  0.394348  0.4  0.473806  0.518269  0.501370   \n",
       "104909  0.455964  0.407315  0.481023  0.5  0.462753  0.369177  0.421769   \n",
       "\n",
       "            x42       x46       x48       x49  \n",
       "148087  0.48113  0.623751  0.607118  0.634293  \n",
       "104909  0.51585  0.693056  0.672425  0.618994  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the reduced features for the training data\n",
    "X_train_reduced_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x12</th>\n",
       "      <th>x20</th>\n",
       "      <th>x23</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x32</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x40</th>\n",
       "      <th>x42</th>\n",
       "      <th>x46</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123113</th>\n",
       "      <td>0.433619</td>\n",
       "      <td>0.524430</td>\n",
       "      <td>0.608014</td>\n",
       "      <td>0.451174</td>\n",
       "      <td>0.410021</td>\n",
       "      <td>0.518398</td>\n",
       "      <td>0.455950</td>\n",
       "      <td>0.470467</td>\n",
       "      <td>0.296940</td>\n",
       "      <td>0.441103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.553541</td>\n",
       "      <td>0.510291</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>0.515677</td>\n",
       "      <td>0.518159</td>\n",
       "      <td>0.832849</td>\n",
       "      <td>0.542068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106577</th>\n",
       "      <td>0.470849</td>\n",
       "      <td>0.340155</td>\n",
       "      <td>0.469993</td>\n",
       "      <td>0.278721</td>\n",
       "      <td>0.442359</td>\n",
       "      <td>0.431604</td>\n",
       "      <td>0.434921</td>\n",
       "      <td>0.674535</td>\n",
       "      <td>0.544612</td>\n",
       "      <td>0.419855</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.432189</td>\n",
       "      <td>0.398144</td>\n",
       "      <td>0.382463</td>\n",
       "      <td>0.366481</td>\n",
       "      <td>0.508459</td>\n",
       "      <td>0.293954</td>\n",
       "      <td>0.491576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x2        x3        x7        x8        x9       x12       x20  \\\n",
       "123113  0.433619  0.524430  0.608014  0.451174  0.410021  0.518398  0.455950   \n",
       "106577  0.470849  0.340155  0.469993  0.278721  0.442359  0.431604  0.434921   \n",
       "\n",
       "             x23       x27       x28  x32       x37       x38       x40  \\\n",
       "123113  0.470467  0.296940  0.441103  0.6  0.553541  0.510291  0.462493   \n",
       "106577  0.674535  0.544612  0.419855  0.6  0.432189  0.398144  0.382463   \n",
       "\n",
       "             x42       x46       x48       x49  \n",
       "123113  0.515677  0.518159  0.832849  0.542068  \n",
       "106577  0.366481  0.508459  0.293954  0.491576  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the reduced features for the testing data\n",
    "X_test_reduced_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training the models using the reduced dimensions (features) from above\n",
    "\n",
    "Using default parameters to establish a baseline with reduced features before proceeding to the **parameter tuning phase** using a **Randomized Search** approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Decision Tree Model\n",
    "\n",
    "Decision trees are primarily leveraged to address both regression and classification cases. \n",
    "- **Classification tree models are used to predict a qualitative response**\n",
    "- **Regression tree models are used to predict a quantitative response**\n",
    "\n",
    "The algorithm constructs a tree using a training dataset where each node is an attribute and the branches are the corresponding values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    21146   2792\n",
      "1.0     2735  13305\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.88      0.88     23938\n",
      "         1.0       0.83      0.83      0.83     16040\n",
      "\n",
      "    accuracy                           0.86     39978\n",
      "   macro avg       0.86      0.86      0.86     39978\n",
      "weighted avg       0.86      0.86      0.86     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Establish the parameters for DECISION TREE and run the model\n",
    "clf_DT_default = DecisionTreeClassifier(random_state=rand_state)\n",
    "clf_DT_default.fit(X_train_reduced_features, y_train)\n",
    "y_pred = clf_DT_default.predict(X_test_reduced_features)\n",
    "\n",
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred)\n",
    "results_df = results_df.append({'Classifier':'Decision Tree'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Default'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Random Forest Model\n",
    "\n",
    "Random Forests are primarily based on Decision trees. \n",
    "- Are an ensemble of decision trees trained using the bagging methodology. \n",
    "- Leverages randomness when growing trees rather than just searching for the best feature when splitting a node.\n",
    "- Seeks the best feature among a random subset of features. \n",
    "- Delivers an enhanced model by trading higher bias for lower variance. \n",
    "\n",
    "Random Forests are useful in gaining a good understanding of feature importance especially when performing feature selection.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    23035    903\n",
      "1.0     1575  14465\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95     23938\n",
      "         1.0       0.94      0.90      0.92     16040\n",
      "\n",
      "    accuracy                           0.94     39978\n",
      "   macro avg       0.94      0.93      0.94     39978\n",
      "weighted avg       0.94      0.94      0.94     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Establish the parameters for RANDOM FOREST and run the model\n",
    "clf_RF_default = RandomForestClassifier(random_state=rand_state)\n",
    "clf_RF_default.fit(X_train_reduced_features, y_train)\n",
    "y_pred = clf_RF_default.predict(X_test_reduced_features)\n",
    "\n",
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred)\n",
    "results_df = results_df.append({'Classifier':'Random Forest'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Default'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model\n",
    "\n",
    "XGBoost is an optimized distributed gradient boosting library designed for high efficiency, flexibility and portability. \n",
    "- Machine learning algorithms are deployed leveraging the Gradient Boosting framework. \n",
    "- It provides a parallel tree boosting approach (GBDT, GBM) which is fast and accurate for solving data science problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    22666   1272\n",
      "1.0     1529  14511\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94     23938\n",
      "         1.0       0.92      0.90      0.91     16040\n",
      "\n",
      "    accuracy                           0.93     39978\n",
      "   macro avg       0.93      0.93      0.93     39978\n",
      "weighted avg       0.93      0.93      0.93     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Establish the parameters for XGBOOST and run the model\n",
    "clf_XGB_default = XGBClassifier(random_state=rand_state)\n",
    "clf_XGB_default.fit(X_train_reduced_features, y_train)\n",
    "y_pred = clf_XGB_default.predict(X_test_reduced_features)\n",
    "\n",
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred)\n",
    "results_df = results_df.append({'Classifier':'XGB'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Default'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>False_Positives</th>\n",
       "      <th>False_Negatives</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>4238</td>\n",
       "      <td>7699</td>\n",
       "      <td>3891880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>3881</td>\n",
       "      <td>8092</td>\n",
       "      <td>4084810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>3094</td>\n",
       "      <td>3000</td>\n",
       "      <td>1530940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>1034</td>\n",
       "      <td>2193</td>\n",
       "      <td>1106840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>XGB</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>1267</td>\n",
       "      <td>1698</td>\n",
       "      <td>861670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Default</td>\n",
       "      <td>2792</td>\n",
       "      <td>2735</td>\n",
       "      <td>1395420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Default</td>\n",
       "      <td>903</td>\n",
       "      <td>1575</td>\n",
       "      <td>796530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>XGB</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Default</td>\n",
       "      <td>1272</td>\n",
       "      <td>1529</td>\n",
       "      <td>777220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier Features Parameters False_Positives False_Negatives  \\\n",
       "0  Logistic Regression     Full    Default            4238            7699   \n",
       "1                  SGD     Full    Default            3881            8092   \n",
       "2        Decision Tree     Full    Default            3094            3000   \n",
       "3        Random Forest     Full    Default            1034            2193   \n",
       "4                  XGB     Full    Default            1267            1698   \n",
       "5        Decision Tree  Reduced    Default            2792            2735   \n",
       "6        Random Forest  Reduced    Default             903            1575   \n",
       "7                  XGB  Reduced    Default            1272            1529   \n",
       "\n",
       "      Cost  \n",
       "0  3891880  \n",
       "1  4084810  \n",
       "2  1530940  \n",
       "3  1106840  \n",
       "4   861670  \n",
       "5  1395420  \n",
       "6   796530  \n",
       "7   777220  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the combined results matrix\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV to choose best parameters\n",
    "\n",
    "In RandomizedSearchCV all hyperparameter values are not tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions. You'll practice using RandomizedSearchCV in this exercise and see how this works.\n",
    "\n",
    "#### Options for RandomizedSearchCV\n",
    "- estimator - A object of that type is instantiated for each grid point.\n",
    "    - Assigned as per the algorithm we are tuning\n",
    "- param_distributions - Dictionary with parameters names (string) as keys and distributions or lists of parameters to try.\n",
    "    - Assigned as per the algorithm we are tuning\n",
    "- scoring - A single string to evaluate the predictions on the test set.\n",
    "    - ['precision' , 'recall' , 'accuracy']\n",
    "- cv - Determines the cross-validation splitting strategy.\n",
    "    - 5\n",
    "- refit - Refit an estimator using the best found parameters on the whole dataset.\n",
    "    - recall\n",
    "n_iterint - Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.\n",
    "    - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['precision'\n",
    "          , 'recall'\n",
    "          , 'accuracy'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['precision', 'recall', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_perf(clf, n_top = 3, clf_name = \"\", verbose=True):\n",
    "    if(verbose):\n",
    "        for n in range(1, n_top+1):\n",
    "            candidates = np.flatnonzero(clf.cv_results_['rank_test_recall'] == n)\n",
    "            for candidate in candidates:\n",
    "                print('Model with rank: {0}'.format(n))\n",
    "                print('Mean validation score (Recall on Test): {0:.3f} (std: {1:.3f})'.format(\n",
    "                    clf.cv_results_['mean_test_recall'][candidate], clf.cv_results_['std_test_recall'][candidate]))\n",
    "                print('ParametersL {0}',format(clf.cv_results_['params'][candidate]))\n",
    "    return{'Classifier': clf_name\n",
    "           , 'Best_Parameters': str(clf.best_params_)\n",
    "           , 'Best_Estimator': str(clf.best_estimator_)\n",
    "#           , 'Accuracy_Mean':clf.cv_results_['mean_test_acc'][clf.best_index_]\n",
    "#           , 'Accuracy_std':clf.cv_results_['std_test_acc'][clf.best_index_]\n",
    "           , 'Precision_Mean':clf.cv_results_['mean_test_precision'][clf.best_index_]\n",
    "           , 'Precision_std':clf.cv_results_['std_test_precision'][clf.best_index_]\n",
    "           , 'Recall_Mean':clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "           , 'Recall_std':clf.cv_results_['std_test_recall'][clf.best_index_]\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "We are tuning for the following parameters for *Decision Tree Classifier*:\n",
    "- max_depth: The maximum depth of the tree.\n",
    "    - [10, 20, 30, None]\n",
    "- max_features: The number of features to consider when looking for the best split\n",
    "    - ['auto', 'sqrt']\n",
    "- criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "    - ['gini','entropy']\n",
    "- min_samples_leaf: The minimum number of samples required to be at a leaf node.  \n",
    "    - [1, 2, 4]\n",
    "- min_samples_split: The minimum number of samples required to split an internal node\n",
    "    - [2, 5, 10]\n",
    "- random_state - If int, random_state is the seed used by the random number generator\n",
    "    - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_DT={'max_depth': [10, 20, 30, None]\n",
    "                     , 'max_features': ['auto', 'sqrt']\n",
    "                     , 'criterion':['gini','entropy']\n",
    "                     , 'min_samples_leaf': [1, 2, 4]\n",
    "                     , 'min_samples_split': [2, 5, 10]\n",
    "                    }\n",
    "\n",
    "clf_DT = DecisionTreeClassifier(random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "random_search_DT = RandomizedSearchCV(estimator=clf_DT\n",
    "                                      , param_distributions=tuned_parameters_DT\n",
    "                                      , cv = 5\n",
    "                                      , scoring = scores\n",
    "                                      , refit ='recall'\n",
    "                                      , n_iter=10\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features=None,\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort='deprecated',\n",
       "                                                    random_state=10,\n",
       "                                                    splitter='best'),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [10, 20, 30, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit='recall',\n",
       "                   return_train_score=False,\n",
       "                   scoring=['precision', 'recall', 'accuracy'], verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_DT.fit(X_train_reduced_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score (Recall on Test): 0.803 (std: 0.003)\n",
      "ParametersL {0} {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 20, 'criterion': 'entropy'}\n",
      "Model with rank: 2\n",
      "Mean validation score (Recall on Test): 0.801 (std: 0.003)\n",
      "ParametersL {0} {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': None, 'criterion': 'gini'}\n",
      "Model with rank: 3\n",
      "Mean validation score (Recall on Test): 0.801 (std: 0.004)\n",
      "ParametersL {0} {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Classifier': 'Decision_Tree',\n",
       " 'Best_Parameters': \"{'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 20, 'criterion': 'entropy'}\",\n",
       " 'Best_Estimator': \"DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\\n                       max_depth=20, max_features='auto', max_leaf_nodes=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=5,\\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\\n                       random_state=10, splitter='best')\",\n",
       " 'Precision_Mean': 0.8196364797229168,\n",
       " 'Precision_std': 0.005316475748262003,\n",
       " 'Recall_Mean': 0.8026143723098986,\n",
       " 'Recall_std': 0.00318892962352034}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_report = report_perf(random_search_DT, n_top = 3, clf_name='Decision_Tree')\n",
    "DT_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "We are tuning the following parameters for Random Forest Classifier:\n",
    "- n_estimators: The number of trees in the forest.\n",
    "    - [100, 200]\n",
    "- max_depth: The maximum depth of the tree.\n",
    "    - [25, 50, None]\n",
    "- criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "    - ['gini','entropy']\n",
    "- min_samples_leaf: The minimum number of samples required to be at a leaf node.\n",
    "    - [1, 25, 50]\n",
    "- max_features: The number of features to consider when looking for the best split.\n",
    "    - [.2, .3, 'auto']\n",
    "- min_samples_split: The minimum number of samples required to split an internal node.\n",
    "    - [2, 4, 8, 10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_RF={'n_estimators':[100, 200]\n",
    "                     , 'max_depth':[25, 50, None]\n",
    "                     , 'criterion':['gini','entropy']\n",
    "                     , 'min_samples_leaf': [1, 25, 50]\n",
    "                     , 'max_features':[.2, .3, 'auto']\n",
    "                     , 'min_samples_split':[2, 4, 8, 10, 12]\n",
    "                    }\n",
    "\n",
    "clf_RF = RandomForestClassifier(random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score (Recall on Test): 0.898 (std: 0.002)\n",
      "ParametersL {0} {'n_estimators': 100, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 50, 'criterion': 'entropy'}\n",
      "Model with rank: 2\n",
      "Mean validation score (Recall on Test): 0.897 (std: 0.002)\n",
      "ParametersL {0} {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 0.2, 'max_depth': 25, 'criterion': 'gini'}\n",
      "Model with rank: 3\n",
      "Mean validation score (Recall on Test): 0.895 (std: 0.001)\n",
      "ParametersL {0} {'n_estimators': 100, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 50, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "random_search_RF = RandomizedSearchCV(estimator=clf_RF\n",
    "                                      , param_distributions=tuned_parameters_RF\n",
    "                                      , cv = 5\n",
    "                                      , scoring = scores\n",
    "                                      , refit = 'recall'\n",
    "                                      , n_iter=10\n",
    "                                     )\n",
    "\n",
    "random_search_RF.fit(X_train_reduced_features, y_train)\n",
    "\n",
    "RF_report = report_perf(random_search_RF, n_top = 3, clf_name='Random_Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Classifier': 'Random_Forest',\n",
       " 'Best_Parameters': \"{'n_estimators': 100, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 50, 'criterion': 'entropy'}\",\n",
       " 'Best_Estimator': \"RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\\n                       criterion='entropy', max_depth=50, max_features='auto',\\n                       max_leaf_nodes=None, max_samples=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=12,\\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\\n                       n_jobs=None, oob_score=False, random_state=10, verbose=0,\\n                       warm_start=False)\",\n",
       " 'Precision_Mean': 0.9359847437548531,\n",
       " 'Precision_std': 0.002862714564129363,\n",
       " 'Recall_Mean': 0.8983976763553722,\n",
       " 'Recall_std': 0.0015151965627338807}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "We are tuning the following parameters for XGBoost:\n",
    "- n_estimators: Number of gradient boosted trees. Equivalent to number of boosting rounds.\n",
    "    - [100, 150, 1000]\n",
    "- learning_rate: Boosting learning rate (xgb’s “eta”)\n",
    "    - [0.01, 0.6, None]\n",
    "- subsample: Subsample ratio of the training instances.\n",
    "    - [0.3, 0.9, None]\n",
    "- max_depth: Maximum depth of a tree.\n",
    "    - [3, 4, 5, 6, 7, 8, 9, None]\n",
    "- colsample_bytree: The subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed.\n",
    "    - [0.5, 0.9, None]\n",
    "- min_child_weight: Minimum sum of instance weight (hessian) needed in a child.\n",
    "    - [1, 2, 3, 4, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_XGB={'n_estimators': [100, 150, 1000]\n",
    "                      , 'learning_rate': [0.01, 0.6, None]\n",
    "                      , 'subsample': [0.3, 0.9, None]\n",
    "                      , 'max_depth': [3, 4, 5, 6, 7, 8, 9, None]\n",
    "                      , 'colsample_bytree': [0.5, 0.9, None]\n",
    "                      , 'min_child_weight': [1, 2, 3, 4, None]\n",
    "                     }\n",
    "\n",
    "clf_XGB = XGBClassifier(random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "random_search_XGB = RandomizedSearchCV(estimator=clf_XGB\n",
    "                                      , param_distributions=tuned_parameters_XGB\n",
    "                                      , cv = 5\n",
    "                                      , scoring = scores\n",
    "                                      , refit ='recall'\n",
    "                                      , n_iter=10\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n...\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'colsample_bytree': [0.5, 0.9, None],\n",
       "                                        'learning_rate': [0.01, 0.6, None],\n",
       "                                        'max_depth': [3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      None],\n",
       "                                        'min_child_weight': [1, 2, 3, 4, None],\n",
       "                                        'n_estimators': [100, 150, 1000],\n",
       "                                        'subsample': [0.3, 0.9, None]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit='recall',\n",
       "                   return_train_score=False,\n",
       "                   scoring=['precision', 'recall', 'accuracy'], verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_XGB.fit(X_train_reduced_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score (Recall on Test): 0.930 (std: 0.001)\n",
      "ParametersL {0} {'subsample': 0.9, 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 9, 'learning_rate': None, 'colsample_bytree': None}\n",
      "Model with rank: 2\n",
      "Mean validation score (Recall on Test): 0.911 (std: 0.002)\n",
      "ParametersL {0} {'subsample': None, 'n_estimators': 100, 'min_child_weight': 4, 'max_depth': 8, 'learning_rate': 0.6, 'colsample_bytree': 0.9}\n",
      "Model with rank: 3\n",
      "Mean validation score (Recall on Test): 0.906 (std: 0.002)\n",
      "ParametersL {0} {'subsample': None, 'n_estimators': 150, 'min_child_weight': 2, 'max_depth': 5, 'learning_rate': 0.6, 'colsample_bytree': 0.9}\n"
     ]
    }
   ],
   "source": [
    "XGB_report = report_perf(random_search_XGB, n_top = 3, clf_name='XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append random_state to the best parameters\n",
    "\n",
    "We assign the best parameters from each of the Random Search to a variable and then add the random state parameter to it. These variables will be passed on to train the models with reduced features and best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_best_params = random_search_DT.best_params_\n",
    "DT_best_params['random_state'] = rand_state\n",
    "\n",
    "RF_best_params = random_search_RF.best_params_\n",
    "RF_best_params['random_state'] = rand_state\n",
    "\n",
    "XGB_best_params = random_search_XGB.best_params_\n",
    "XGB_best_params['random_state'] = rand_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model with the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "- The best parameter (with random_state) from the previous step is chosen as classifier\n",
    "- Confusion Matrix and Classification Reports are displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    21323   2615\n",
      "1.0     3075  12965\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88     23938\n",
      "         1.0       0.83      0.81      0.82     16040\n",
      "\n",
      "    accuracy                           0.86     39978\n",
      "   macro avg       0.85      0.85      0.85     39978\n",
      "weighted avg       0.86      0.86      0.86     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_DT_best = DecisionTreeClassifier(**DT_best_params)\n",
    "clf_DT_best.fit(X_train_reduced_features, y_train)\n",
    "\n",
    "y_pred_DT = clf_DT_best.predict(X_test_reduced_features)\n",
    "\n",
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred_DT)\n",
    "results_df = results_df.append({'Classifier':'Decision Tree'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Best'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "- The best estimator from the previous step is chosen as classifier\n",
    "- Confusion Matrix and Classification Reports are displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    22966    972\n",
      "1.0     1583  14457\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95     23938\n",
      "         1.0       0.94      0.90      0.92     16040\n",
      "\n",
      "    accuracy                           0.94     39978\n",
      "   macro avg       0.94      0.93      0.93     39978\n",
      "weighted avg       0.94      0.94      0.94     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_RF_best = RandomForestClassifier(**RF_best_params)\n",
    "clf_RF_best.fit(X_train_reduced_features, y_train)\n",
    "\n",
    "y_pred_RF = clf_RF_best.predict(X_test_reduced_features)\n",
    "\n",
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred_RF)\n",
    "results_df = results_df.append({'Classifier':'Random Forest'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Best'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "- The best estimator from the previous step is chosen as classifier\n",
    "- Confusion Matrix and Classification Reports are displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    23086    852\n",
      "1.0     1080  14960\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     23938\n",
      "         1.0       0.95      0.93      0.94     16040\n",
      "\n",
      "    accuracy                           0.95     39978\n",
      "   macro avg       0.95      0.95      0.95     39978\n",
      "weighted avg       0.95      0.95      0.95     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_XGB_Best = XGBClassifier(**XGB_best_params)\n",
    "clf_XGB_Best.fit(X_train_reduced_features, y_train)\n",
    "\n",
    "y_pred_XGB = clf_XGB_Best.predict(X_test_reduced_features)\n",
    "\n",
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred_XGB)\n",
    "results_df = results_df.append({'Classifier':'XGB'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Best'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models\n",
    "\n",
    "The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\n",
    "\n",
    "Stacking, also called Super Learning or Stacked Regression, is a class of algorithms that involves training a second-level \"metalearner\" to find the optimal combination of the base learners. Unlike bagging and boosting, the goal in stacking is to ensemble strong, diverse sets of learners together.\n",
    "\n",
    "![title](img/EnsembleModels3.png) \n",
    "\n",
    "References: https://www.kdnuggets.com/2019/01/ensemble-learning-5-main-approaches.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model 1 - Stacking\n",
    "\n",
    "The first ensemble technique uses the vecstack package for stacking. It is compatible with the scikit-learn API to automate OOF computation, prediction and bagging using multiple models and stages.\n",
    "\n",
    "![title](img/EnsembleModels.png) \n",
    "\n",
    "Reference: https://blogs.sas.com/content/subconsciousmusings/2017/05/18/stacked-ensemble-models-win-data-science-competitions/\n",
    "\n",
    "Below, we use the Best Decision Tree and Random Forest classifiers in Stage 1. The Stage 1 output is passed on to Stage 2 which uses the XGBoost classifier with the best parameters. Finally, Logistic Regression is used as the Meta Classifier to predict the outcome and compare against the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [recall_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [DecisionTreeClassifier]\n",
      "    fold  0:  [0.79536839]\n",
      "    fold  1:  [0.80399365]\n",
      "    fold  2:  [0.80175512]\n",
      "    fold  3:  [0.79553564]\n",
      "    ----\n",
      "    MEAN:     [0.79916320] + [0.00379510]\n",
      "    FULL:     [0.79914379]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.89467612]\n",
      "    fold  1:  [0.89840421]\n",
      "    fold  2:  [0.89728374]\n",
      "    fold  3:  [0.89519542]\n",
      "    ----\n",
      "    MEAN:     [0.89638987] + [0.00151824]\n",
      "    FULL:     [0.89638189]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_1 = [clf_DT_best\n",
    "            , clf_RF_best]\n",
    "\n",
    "# Get out-of-fold predictions from 1-level models\n",
    "S_1_train, S_1_test = stacking(models_1\n",
    "                               , X_train_reduced_features\n",
    "                               , y_train\n",
    "                               , X_test_reduced_features\n",
    "                               , regression = True\n",
    "                               , metric=recall_score\n",
    "                               , verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [recall_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [1]\n",
      "\n",
      "model  0:     [XGBClassifier]\n",
      "    fold  0:  [0.89467612]\n",
      "    fold  1:  [0.89840421]\n",
      "    fold  2:  [0.89728374]\n",
      "    fold  3:  [0.89519542]\n",
      "    ----\n",
      "    MEAN:     [0.89638987] + [0.00151824]\n",
      "    FULL:     [0.89638189]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize 2-level models\n",
    "models_2 = [clf_XGB_Best]\n",
    "\n",
    "# Get out-of-fold predictions from 2-level models\n",
    "S_2_train, S_2_test = stacking(models_2\n",
    "                               , S_1_train\n",
    "                               , y_train\n",
    "                               , S_1_test\n",
    "                               , regression = True\n",
    "                               , metric=recall_score\n",
    "                               , verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 3-level model\n",
    "model = LogisticRegression(random_state=rand_state)\n",
    "# Fit\n",
    "model.fit(S_2_train, y_train)\n",
    "# Get final prediction\n",
    "y_pred_ensemble = model.predict(S_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    22863   1075\n",
      "1.0     1482  14558\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95     23938\n",
      "         1.0       0.93      0.91      0.92     16040\n",
      "\n",
      "    accuracy                           0.94     39978\n",
      "   macro avg       0.94      0.93      0.93     39978\n",
      "weighted avg       0.94      0.94      0.94     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred_ensemble)\n",
    "results_df = results_df.append({'Classifier':'Ensemble_1'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Best'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076059850374065"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model 2\n",
    "\n",
    "The second ensemble technique uses the StackingCVClassifier from mlxtend package. \n",
    "\n",
    "![title](img/Ensemble_StackingCVClassifier.png) \n",
    "\n",
    "Reference: http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/\n",
    "\n",
    "In this model, we pass all our 3 best models (Decision Tree, Random Forest and XGBoost) together in 1 stage. Similar to the previous ensemble model, we use Logistic Regression as our Meta-Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf = StackingCVClassifier(classifiers=[clf_DT_best, clf_RF_best, clf_XGB_Best]\n",
    "                            , use_probas=True\n",
    "                            , random_state= rand_state\n",
    "                            , meta_classifier=LogisticRegression(random_state=rand_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['Decision Tree', 'Random Forest', 'XGBoost', 'Stacking Classifier']\n",
    "clf_list = [clf_DT_best, clf_RF_best, clf_XGB_Best, sclf]\n",
    "    \n",
    "sclf.fit(X_train_reduced_features, y_train)\n",
    "y_pred_sclf = sclf.predict(X_test_reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    23077    861\n",
      "1.0     1092  14948\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96     23938\n",
      "         1.0       0.95      0.93      0.94     16040\n",
      "\n",
      "    accuracy                           0.95     39978\n",
      "   macro avg       0.95      0.95      0.95     39978\n",
      "weighted avg       0.95      0.95      0.95     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred_sclf)\n",
    "results_df = results_df.append({'Classifier':'Ensemble_2'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Best'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model 3\n",
    "\n",
    "Stack of estimators with a final classifier. Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.\n",
    "\n",
    "![title](img/StackOfEstimatorsWithFinalClassifier.png)\n",
    "\n",
    "Reference: https://towardsdatascience.com/stacking-classifiers-for-higher-predictive-performance-566f963e4840\n",
    "\n",
    "\n",
    "In this step, we use multi-layer classsifier technique. In multi-layer classifier, we assign the final estimator to a stacking classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = StackingClassifier(estimators=[('rf', clf_RF_best)\n",
    "                                            , ('xgb', clf_XGB_Best)]\n",
    "                                , final_estimator=LogisticRegression(random_state=rand_state)\n",
    "                               )\n",
    "\n",
    "multi_layer_regressor = StackingClassifier(estimators=[('dt', clf_DT_best)]\n",
    "                                          , final_estimator=final_layer\n",
    "                                         )\n",
    "\n",
    "multi_layer_regressor.fit(X_train_reduced_features, y_train)\n",
    "\n",
    "y_pred_multi = multi_layer_regressor.predict(X_test_reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    21583   2355\n",
      "1.0     3417  12623\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.90      0.88     23938\n",
      "         1.0       0.84      0.79      0.81     16040\n",
      "\n",
      "    accuracy                           0.86     39978\n",
      "   macro avg       0.85      0.84      0.85     39978\n",
      "weighted avg       0.86      0.86      0.85     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred_multi)\n",
    "results_df = results_df.append({'Classifier':'Ensemble_3'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Best'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model 4\n",
    "\n",
    "Ensemble Model 4 is similar to Ensemble Model 3. However, in this step, we use a single stacking layer with Decision Tree, Random Forest and XGBoost with the best parameters passed as ensemble estimators. \n",
    "\n",
    "![title](img/EnsembleModels2.png)\n",
    "\n",
    "Reference: https://blogs.sas.com/content/subconsciousmusings/2017/05/18/stacked-ensemble-models-win-data-science-competitions/\n",
    "\n",
    "\n",
    "SGD is chosen as the final estimator or meta-classifier as discussed in Ensemble Model 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=None,\n",
       "                   estimators=[('rf',\n",
       "                                RandomForestClassifier(bootstrap=True,\n",
       "                                                       ccp_alpha=0.0,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='entropy',\n",
       "                                                       max_depth=50,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       max_samples=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=12,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=No...\n",
       "                                                 class_weight=None,\n",
       "                                                 early_stopping=False,\n",
       "                                                 epsilon=0.1, eta0=0.0,\n",
       "                                                 fit_intercept=True,\n",
       "                                                 l1_ratio=0.15,\n",
       "                                                 learning_rate='optimal',\n",
       "                                                 loss='hinge', max_iter=1000,\n",
       "                                                 n_iter_no_change=5,\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 power_t=0.5, random_state=10,\n",
       "                                                 shuffle=True, tol=0.001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_estimators = [('rf', clf_RF_best)\n",
    "                       , ('xgb', clf_XGB_Best)\n",
    "                       , ('dt', clf_DT_best)\n",
    "#                       , ('logistic', LogisticRegression(random_state=rand_state))\n",
    "                      ]\n",
    "\n",
    "clf_ensemble = StackingClassifier(estimators=ensemble_estimators\n",
    "                                  , final_estimator=SGDClassifier(random_state=rand_state)\n",
    "#                                  , final_estimator=SVC(gamma = 0.5, random_state=rand_state)\n",
    "                                 )\n",
    "\n",
    "clf_ensemble.fit(X_train_reduced_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ens = clf_ensemble.predict(X_test_reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    23079    859\n",
      "1.0     1076  14964\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     23938\n",
      "         1.0       0.95      0.93      0.94     16040\n",
      "\n",
      "    accuracy                           0.95     39978\n",
      "   macro avg       0.95      0.95      0.95     39978\n",
      "weighted avg       0.95      0.95      0.95     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred_ens)\n",
    "results_df = results_df.append({'Classifier':'Ensemble_4'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Best'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model 5\n",
    "\n",
    "Ensemble model 5 is the same as Ensemble Model 4. The only difference is that we are using SMV (SVC) as the final estimator here instead of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=None,\n",
       "                   estimators=[('rf',\n",
       "                                RandomForestClassifier(bootstrap=True,\n",
       "                                                       ccp_alpha=0.0,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='entropy',\n",
       "                                                       max_depth=50,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       max_samples=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=12,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=No...\n",
       "                                                       presort='deprecated',\n",
       "                                                       random_state=10,\n",
       "                                                       splitter='best'))],\n",
       "                   final_estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                       class_weight=None, coef0=0.0,\n",
       "                                       decision_function_shape='ovr', degree=3,\n",
       "                                       gamma=0.5, kernel='rbf', max_iter=-1,\n",
       "                                       probability=False, random_state=10,\n",
       "                                       shrinking=True, tol=0.001,\n",
       "                                       verbose=False),\n",
       "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_estimators_5 = [('rf', clf_RF_best)\n",
    "                       , ('xgb', clf_XGB_Best)\n",
    "                       , ('dt', clf_DT_best)\n",
    "#                       , ('logistic', LogisticRegression(random_state=rand_state))\n",
    "                      ]\n",
    "\n",
    "clf_ensemble_5 = StackingClassifier(estimators=ensemble_estimators_5\n",
    "#                                   , final_estimator=SGDClassifier(random_state=rand_state)\n",
    "                                    , final_estimator=SVC(gamma = 0.5, random_state=rand_state)\n",
    "                                 )\n",
    "\n",
    "clf_ensemble_5.fit(X_train_reduced_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ens_5 = clf_ensemble_5.predict(X_test_reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix::\n",
      "\n",
      "col_0    0.0    1.0\n",
      "y                  \n",
      "0.0    23067    871\n",
      "1.0     1060  14980\n",
      "\n",
      "Classification Report::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     23938\n",
      "         1.0       0.95      0.93      0.94     16040\n",
      "\n",
      "    accuracy                           0.95     39978\n",
      "   macro avg       0.95      0.95      0.95     39978\n",
      "weighted avg       0.95      0.95      0.95     39978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(FP, FN, Cost) = confusion_mat(y_test, y_pred_ens_5)\n",
    "results_df = results_df.append({'Classifier':'Ensemble_5'\n",
    "                                    , 'Features':'Reduced'\n",
    "                                    , 'Parameters': 'Best'\n",
    "                                    , 'False_Positives': FP\n",
    "                                    , 'False_Negatives': FN\n",
    "                                    , 'Cost': Cost\n",
    "                                   }\n",
    "                                   , ignore_index=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>False_Positives</th>\n",
       "      <th>False_Negatives</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Ensemble_5</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Best</td>\n",
       "      <td>871</td>\n",
       "      <td>1060</td>\n",
       "      <td>538710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Ensemble_4</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Best</td>\n",
       "      <td>859</td>\n",
       "      <td>1076</td>\n",
       "      <td>546590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>XGB</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Best</td>\n",
       "      <td>852</td>\n",
       "      <td>1080</td>\n",
       "      <td>548520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Ensemble_2</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Best</td>\n",
       "      <td>861</td>\n",
       "      <td>1092</td>\n",
       "      <td>554610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Ensemble_1</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Best</td>\n",
       "      <td>1075</td>\n",
       "      <td>1482</td>\n",
       "      <td>751750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>XGB</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Default</td>\n",
       "      <td>1272</td>\n",
       "      <td>1529</td>\n",
       "      <td>777220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Default</td>\n",
       "      <td>903</td>\n",
       "      <td>1575</td>\n",
       "      <td>796530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Best</td>\n",
       "      <td>972</td>\n",
       "      <td>1583</td>\n",
       "      <td>801220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>XGB</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>1267</td>\n",
       "      <td>1698</td>\n",
       "      <td>861670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>1034</td>\n",
       "      <td>2193</td>\n",
       "      <td>1106840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Default</td>\n",
       "      <td>2792</td>\n",
       "      <td>2735</td>\n",
       "      <td>1395420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>3094</td>\n",
       "      <td>3000</td>\n",
       "      <td>1530940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Best</td>\n",
       "      <td>2615</td>\n",
       "      <td>3075</td>\n",
       "      <td>1563650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Ensemble_3</td>\n",
       "      <td>Reduced</td>\n",
       "      <td>Best</td>\n",
       "      <td>2355</td>\n",
       "      <td>3417</td>\n",
       "      <td>1732050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>4238</td>\n",
       "      <td>7699</td>\n",
       "      <td>3891880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>Full</td>\n",
       "      <td>Default</td>\n",
       "      <td>3881</td>\n",
       "      <td>8092</td>\n",
       "      <td>4084810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier Features Parameters False_Positives False_Negatives  \\\n",
       "15           Ensemble_5  Reduced       Best             871            1060   \n",
       "14           Ensemble_4  Reduced       Best             859            1076   \n",
       "10                  XGB  Reduced       Best             852            1080   \n",
       "12           Ensemble_2  Reduced       Best             861            1092   \n",
       "11           Ensemble_1  Reduced       Best            1075            1482   \n",
       "7                   XGB  Reduced    Default            1272            1529   \n",
       "6         Random Forest  Reduced    Default             903            1575   \n",
       "9         Random Forest  Reduced       Best             972            1583   \n",
       "4                   XGB     Full    Default            1267            1698   \n",
       "3         Random Forest     Full    Default            1034            2193   \n",
       "5         Decision Tree  Reduced    Default            2792            2735   \n",
       "2         Decision Tree     Full    Default            3094            3000   \n",
       "8         Decision Tree  Reduced       Best            2615            3075   \n",
       "13           Ensemble_3  Reduced       Best            2355            3417   \n",
       "0   Logistic Regression     Full    Default            4238            7699   \n",
       "1                   SGD     Full    Default            3881            8092   \n",
       "\n",
       "       Cost  \n",
       "15   538710  \n",
       "14   546590  \n",
       "10   548520  \n",
       "12   554610  \n",
       "11   751750  \n",
       "7    777220  \n",
       "6    796530  \n",
       "9    801220  \n",
       "4    861670  \n",
       "3   1106840  \n",
       "5   1395420  \n",
       "2   1530940  \n",
       "8   1563650  \n",
       "13  1732050  \n",
       "0   3891880  \n",
       "1   4084810  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by = 'Cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- https://jamesrledoux.com/code/imputation\n",
    "- https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/\n",
    "- https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas\n",
    "- https://stackoverflow.com/questions/60393024/rfecv-for-classification-giving-keyerror-weight\n",
    "- https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html\n",
    "- https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python\n",
    "- https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n",
    "- https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
