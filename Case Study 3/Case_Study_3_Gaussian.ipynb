{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Case Study 3 Gaussian.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjschueder/7333QTW/blob/master/Case%20Study%203/Case_Study_3_Gaussian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XffGjp9PFPsR",
        "colab_type": "text"
      },
      "source": [
        "## CASE 3/CASE 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By6ZwNXFFPsU",
        "colab_type": "text"
      },
      "source": [
        "### Summary/Introduction blurb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aPLB9eDFPsf",
        "colab_type": "text"
      },
      "source": [
        "### Data Processing \n",
        "\n",
        "We received the data in an \"R data format\" file. Since we opted to do this analysis in Python, the Python package \"pyreadr\" was used to read the data into a Python Pandas dataframe; we then converted the dataframe to a comma separated file (CSV) to store on GitHub for ease of use. Each execution of this Jupyter notebook reads the data from the CSV file on GitHub. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro7mn6GTFPsh",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/jjschueder/7333QTW/blob/master/Case%20Study%203/Py%20read%20R.JPG -- DO WE NEED THIS LINK? I dont think so as it refers to an image file with a *.jpg extension.  Perhaps Joe can clarify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIdt1O-CFPsm",
        "colab_type": "code",
        "outputId": "53e39473-1370-4b92-f46c-9047455aab49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "#import all packages needed\n",
        "import pandas as pd\n",
        "# Install a conda package in the current Jupyter kernel\n",
        "import sys\n",
        "!pip install pyreadr\n",
        "import pyreadr\n",
        "from pandas_profiling import ProfileReport"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyreadr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/09/52ca21f4888ca56731dbe15ca59cda5ccbea72ec2e4a3b97c286de533bde/pyreadr-0.2.9-cp36-cp36m-manylinux1_x86_64.whl (261kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>0.24.0 in /usr/local/lib/python3.6/dist-packages (from pyreadr) (1.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>0.24.0->pyreadr) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>0.24.0->pyreadr) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>0.24.0->pyreadr) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>0.24.0->pyreadr) (1.12.0)\n",
            "Installing collected packages: pyreadr\n",
            "Successfully installed pyreadr-0.2.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpV4RoM4FPsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the dataset - ONLY DONE ONCE, included for reference\n",
        "# result = pyreadr.read_r(r'C:\\Users\\jjsch\\Downloads\\Week_5_Materials_2\\data.Rda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCw2cT3YFPs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to a dataframe - ONLY DONE ONCE, for reference\n",
        "# df = result[\"emailDFrp\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTHogra_FPs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export dataframe to CSV - ONLY DONE ONCE, for reference\n",
        "# df.to_csv(r'C:\\Users\\jjsch\\Downloads\\Week_5_Materials_2\\data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clHFQ2nkFPs_",
        "colab_type": "code",
        "outputId": "be513e4d-7de3-4a14-fa43-a712133bb377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "# view data \n",
        "df = pd.read_csv(r'https://raw.githubusercontent.com/jjschueder/7333QTW/master/Case%20Study%203/data.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>isSpam</th>\n",
              "      <th>isRe</th>\n",
              "      <th>underscore</th>\n",
              "      <th>priority</th>\n",
              "      <th>isInReplyTo</th>\n",
              "      <th>sortedRec</th>\n",
              "      <th>subPunc</th>\n",
              "      <th>multipartText</th>\n",
              "      <th>hasImages</th>\n",
              "      <th>isPGPsigned</th>\n",
              "      <th>subSpamWords</th>\n",
              "      <th>noHost</th>\n",
              "      <th>numEnd</th>\n",
              "      <th>isYelling</th>\n",
              "      <th>isOrigMsg</th>\n",
              "      <th>isDear</th>\n",
              "      <th>isWrote</th>\n",
              "      <th>numLines</th>\n",
              "      <th>bodyCharCt</th>\n",
              "      <th>subExcCt</th>\n",
              "      <th>subQuesCt</th>\n",
              "      <th>numAtt</th>\n",
              "      <th>numRec</th>\n",
              "      <th>perCaps</th>\n",
              "      <th>hour</th>\n",
              "      <th>perHTML</th>\n",
              "      <th>subBlanks</th>\n",
              "      <th>forwards</th>\n",
              "      <th>avgWordLen</th>\n",
              "      <th>numDlr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>50</td>\n",
              "      <td>1554</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.451039</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.376623</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>26</td>\n",
              "      <td>873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.491289</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.555556</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>38</td>\n",
              "      <td>1713</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.436096</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.817164</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>32</td>\n",
              "      <td>1095</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.090909</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.918919</td>\n",
              "      <td>3.125000</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>31</td>\n",
              "      <td>1021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.116643</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.217391</td>\n",
              "      <td>6.451613</td>\n",
              "      <td>4.234940</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  isSpam isRe underscore  ...  subBlanks  forwards avgWordLen numDlr\n",
              "0           0       0    T          F  ...  12.500000  0.000000   4.376623      3\n",
              "1           1       0    F          F  ...   8.000000  0.000000   4.555556      0\n",
              "2           2       0    F          F  ...   8.000000  0.000000   4.817164      0\n",
              "3           3       0    F          F  ...  18.918919  3.125000   4.714286      0\n",
              "4           4       0    T          F  ...  15.217391  6.451613   4.234940      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-mf-4DiFPtF",
        "colab_type": "text"
      },
      "source": [
        "Our initial review of the data shows many columns are formated as a \"logical\" data type of TRUE or FALSE. Machine learning classificaton algorithms need numeric variables. Therefore, we converted the TRUE/FALSE variables to a numeric representation: TRUE == 1; FALSE == 0. The remaining variables are numeric as they represent percentages, counts, and hours of the day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU7F-0EaFPtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform logical data to numeric data\n",
        "# df['isSpam'] = df['isSpam'].map({'T': 1, 'F': 0})\n",
        "df['isRe'] = df['isRe'].map({'T': 1, 'F': 0})             \n",
        "df['underscore'] = df['underscore'].map({'T': 1, 'F': 0})       \n",
        "df['priority'] = df['priority'].map({'T': 1, 'F': 0})         \n",
        "df['isInReplyTo'] = df['isInReplyTo'].map({'T': 1, 'F': 0})      \n",
        "df['sortedRec'] = df['sortedRec'].map({'T': 1, 'F': 0})        \n",
        "df['subPunc'] = df['subPunc'].map({'T': 1, 'F': 0})          \n",
        "df['multipartText'] = df['multipartText'].map({'T': 1, 'F': 0})    \n",
        "df['hasImages'] = df['hasImages'].map({'T': 1, 'F': 0})        \n",
        "df['isPGPsigned'] = df['isPGPsigned'].map({'T': 1, 'F': 0})       \n",
        "df['subSpamWords'] = df['subSpamWords'].map({'T': 1, 'F': 0})      \n",
        "df['noHost'] = df['noHost'].map({'T': 1, 'F': 0})            \n",
        "df['numEnd'] = df['numEnd'].map({'T': 1, 'F': 0})            \n",
        "df['isYelling'] = df['isYelling'].map({'T': 1, 'F': 0})         \n",
        "df['isOrigMsg'] = df['isOrigMsg'].map({'T': 1, 'F': 0})         \n",
        "df['isDear'] = df['isDear'].map({'T': 1, 'F': 0})            \n",
        "df['isWrote'] = df['isWrote'].map({'T': 1, 'F': 0})    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beMC8CeRFPtK",
        "colab_type": "text"
      },
      "source": [
        "### Exploratory Data Analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ27U5Q5FPtL",
        "colab_type": "code",
        "outputId": "384c62f8-4e7e-4d90-e953-0db93a68e490",
        "colab": {}
      },
      "source": [
        "type(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCx2d3L0FPtO",
        "colab_type": "text"
      },
      "source": [
        "After confirming proper the proper type of data frame, we conducted exploratory data analysis to better understand the dataset. Our first step was to understand the variables and their associated meaning in relation to an email message. The data dictionary below provides a summary. Note, the target variable to predict - IsSpam - is included. There is a record id - Unnamed: 0 - which is not necessary for our analysi,s but we retained it for reference as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrNQTBiDFPtP",
        "colab_type": "text"
      },
      "source": [
        "#### Data Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syHbcM-JFPtP",
        "colab_type": "code",
        "outputId": "334a1e41-52a0-4bed-fbe6-d19cd190e223",
        "colab": {}
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'isSpam', 'isRe', 'underscore', 'priority', 'isInReplyTo',\n",
              "       'sortedRec', 'subPunc', 'multipartText', 'hasImages', 'isPGPsigned',\n",
              "       'subSpamWords', 'noHost', 'numEnd', 'isYelling', 'isOrigMsg', 'isDear',\n",
              "       'isWrote', 'numLines', 'bodyCharCt', 'subExcCt', 'subQuesCt', 'numAtt',\n",
              "       'numRec', 'perCaps', 'hour', 'perHTML', 'subBlanks', 'forwards',\n",
              "       'avgWordLen', 'numDlr'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYhrpiHNFPtT",
        "colab_type": "text"
      },
      "source": [
        "| VARIABLE | DEFINITION |\n",
        "|-|-|\n",
        "| isSpam | TRUE if email classified as spam |\n",
        "| isRe | TRUE if Re: appears at the start of subject line |\n",
        "| numLines | number of lines in body of message |\n",
        "| bodyCharCt | number of characters in the body of message |\n",
        "| underscore | TRUE if email address in From field of header contains underscore |\n",
        "| subExcCt | number of exclamation marks in subject |\n",
        "| subQuesCt | number of question marks in subject |\n",
        "| numAtt | number of attachments in message |\n",
        "| priority | TRUE if Priority key is present in header |\n",
        "| numRec | number of recipients of message, including CCs |\n",
        "| perCaps | percentage of capitals among all letters in message |\n",
        "| isInReplyTo | TRUE if the In-Reply-To key is present in header |\n",
        "| sortedRec | TRUE if recipients' email addresses are sorted |\n",
        "| subPunc | TRUE if words in subject have punctuation or numbers embedded (i.e. w!se) |\n",
        "| hour | hour of the day in the Date field |\n",
        "| multipartText | TRUE if MIME type is multipart/text |\n",
        "| hasImages | TRUE if message contains images |\n",
        "| isPGPsigned | TRUE if message contains a PGP (encryption) signature |\n",
        "| perMTML | percentage of characters in HTML tags in message compared to all characters |\n",
        "| subSpamWords | TRUE if subject contains one of the words in spam word vector |\n",
        "| subBlanks | percentage of blanks in subject |\n",
        "| noHost | TRUE if there is no hostname in Message-Id key in header |\n",
        "| numEnd | TRUE if sender's email address (before @) ends in number |\n",
        "| isYelling | TRUE if subject is in all capital letters |\n",
        "| forwards | number of forward symbols in a line of the body (i.e. >>> xxx contains 3) |\n",
        "| isOrigMsg | TRUE if message body contains phrase \"original message\" |\n",
        "| isDear | TRUE if message body contains word \"dear\" |\n",
        "| isWrote | TRUE if message contains phrase \"wrote:\" |\n",
        "| avgWordLen | average length of words in message |\n",
        "| numDlr | number of dollar signs in message |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfr3M1yHFPtU",
        "colab_type": "text"
      },
      "source": [
        "#### Data profiling\n",
        "\n",
        "Next, we dug deeper into the exploratory analysis to understand descriptive statistics, data distrutions, and corrleation between our variables. Using standard Python command and a Python package called Pandas Profiling, we found some notable characters about select variables.\n",
        "\n",
        "Missing data: \n",
        "* subSpam (7 missing), noHost (1 missing), isYelling (7 missing), subExcCt (20 missing), subQuesCt (20 missing), numRec (20 missing), and subBlanks (20 missing). \n",
        "* Missing values and imputation strategy outlined below.\n",
        "\n",
        "Outliers / Odd data:\n",
        "* Outliers correlated with Spam: numRec with 311 receipents; 100% capital letters in email (>80% was spam threshold for perCaps); 100% HTML characters (>97% was spam threshold for perHTML); 86% blanks in subject (>25% was spam threshold for subBlanks), and average word length of 26 is a spam outlier.\n",
        "* Outliers not necessarily correlated with Spam: count of question marks in subject (8 and 12 outliers were not spam); greatest number of attachments at 18 (not spam); number of forwards at 99 (not spam); and large number of dollar signs at 1977 (not spam).\n",
        "\n",
        "WHAT OTHER INTERESTING THINGS TO NOTE FROM PROFILE\n",
        "* Distributions\n",
        "* Other thoughts?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGvUZ8aIFPt4",
        "colab_type": "text"
      },
      "source": [
        "#### Missing Values and Imputation Strategy\n",
        "As noted above, we addressed missing values in our dataset to improve our results. We opted to drop the 20 rows missing in the “subExcCt”, “subQuesCt”, and “subBlanks” columns. The missing data associated with these three columns was absent in the same rows; therefore, only 20 records were removed in addressing those columns. We felt this was an appropriate step given it represented only 0.2% of the data. Dropping these records also removed the seven missing values of “isYelling” and “subSpamWords.”\n",
        "\n",
        "The number of recipients (numRec) has the most missing values at 282. We decided to impute the missing values with the mean number of recipients. This imputation was done after we split the data into training and testing datasets. The mean was calculated from the training dataset only. We felt this would most closely mimic a production environment and limit data leakage between the training and test sets. The remaining missing data point was one value for “noHost\"; we imputed this with the most frequently occurring value (mode) of False (0). **{IS THIS WHAT WE DID!??}{ OR WE CAN ASSIGN THE VALUE SINCE WE KNOW THE MISSING ONE IS SPAM ... I think all the SPAMs have a noHost of TRUE}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP4QvLuPFPt4",
        "colab_type": "code",
        "outputId": "218c3684-00a9-4ec2-b3e9-18b9ccfebcb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        }
      },
      "source": [
        "# Missing Data Summary\n",
        "countOfNan = pd.Series(df.isnull().sum()) \n",
        "DataType = pd.Series(df.dtypes) \n",
        "  \n",
        "frame = { 'datatype': DataType, 'count of Nan': countOfNan } \n",
        "result = pd.DataFrame(frame) \n",
        "print(result)\n",
        "\n",
        "# remove NaNs\n",
        "dfNoNa = df[~df['subQuesCt'].isnull()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              datatype  count of Nan\n",
            "Unnamed: 0       int64             0\n",
            "isSpam           int64             0\n",
            "isRe             int64             0\n",
            "underscore       int64             0\n",
            "priority         int64             0\n",
            "isInReplyTo      int64             0\n",
            "sortedRec        int64             0\n",
            "subPunc          int64             0\n",
            "multipartText    int64             0\n",
            "hasImages        int64             0\n",
            "isPGPsigned      int64             0\n",
            "subSpamWords   float64             7\n",
            "noHost         float64             1\n",
            "numEnd           int64             0\n",
            "isYelling      float64             7\n",
            "isOrigMsg        int64             0\n",
            "isDear           int64             0\n",
            "isWrote          int64             0\n",
            "numLines         int64             0\n",
            "bodyCharCt       int64             0\n",
            "subExcCt       float64            20\n",
            "subQuesCt      float64            20\n",
            "numAtt         float64             0\n",
            "numRec         float64           282\n",
            "perCaps        float64             0\n",
            "hour           float64             0\n",
            "perHTML        float64             0\n",
            "subBlanks      float64            20\n",
            "forwards       float64             0\n",
            "avgWordLen     float64             0\n",
            "numDlr           int64             0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4XeXGWsFPt9",
        "colab_type": "text"
      },
      "source": [
        "### Explanation of Data Split, equivalent to R split()\n",
        "\n",
        "In the Python sklearn package, \"Stratified Shuffle Split\" provides train/test indices to split data in train/test sets.\n",
        "This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html  \n",
        "\n",
        "The settings we used for training are 1 fold using eighty percent of the data for training. Twenty percent of the data will be used to test the initial model. \n",
        "\n",
        "** DID WE USE STRATIFIED SHUFFLE SPLIT OR JUST SHUFFLE SPLIT ?? It looks like we commented out Strat Shuffle Split. Why did we decide to do that? Why was Shuffle Split better than Strat Shuffle Split??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBm-aDOnFPt-",
        "colab_type": "code",
        "outputId": "c1f19023-763d-4b50-cd78-9c64ae42e00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# now divide the data into test and train using scikit learn built-ins\n",
        "from sklearn.model_selection import StratifiedShuffleSplit \n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "cvx = ShuffleSplit(n_splits=10, test_size=0.20, random_state=101)\n",
        "#cv = StratifiedShuffleSplit(n_splits=10,train_size=0.8)\n",
        "print (cvx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ShuffleSplit(n_splits=10, random_state=101, test_size=0.2, train_size=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DALBKW3FPuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['isRe', 'underscore', 'priority', 'isInReplyTo',\n",
        "            'sortedRec', 'subPunc', 'multipartText', 'hasImages', 'isPGPsigned',\n",
        "            'subSpamWords', 'noHost', 'numEnd', 'isYelling', 'isOrigMsg', 'isDear',\n",
        "            'isWrote', 'numLines', 'bodyCharCt', 'subExcCt', 'subQuesCt', 'numAtt',\n",
        "            'numRec', 'perCaps', 'hour', 'perHTML', 'subBlanks', 'forwards',\n",
        "            'avgWordLen', 'numDlr']\n",
        "\n",
        "X = dfNoNa[features].copy()\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "#scaler.fit(X2)\n",
        "\n",
        "#This makes our model's coefficients take on the same scale for accurate feature importance analysis\n",
        "#Notice we scaled the data before the cross validation\n",
        "#X = scaler.transform(X2)\n",
        "\n",
        "Y= dfNoNa[['isSpam']].copy()\n",
        "y = Y.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ztoH_lNM7v",
        "colab_type": "code",
        "outputId": "3469d910-40e3-4e46-9b52-5cf61235bdb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "\n",
        "# Missing Data Summary\n",
        "countOfNan = pd.Series(X.isnull().sum()) \n",
        "DataType = pd.Series(X.dtypes) \n",
        "  \n",
        "frame = { 'datatype': DataType, 'count of Nan': countOfNan } \n",
        "result = pd.DataFrame(frame) \n",
        "print(result)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              datatype  count of Nan\n",
            "isRe             int64             0\n",
            "underscore       int64             0\n",
            "priority         int64             0\n",
            "isInReplyTo      int64             0\n",
            "sortedRec        int64             0\n",
            "subPunc          int64             0\n",
            "multipartText    int64             0\n",
            "hasImages        int64             0\n",
            "isPGPsigned      int64             0\n",
            "subSpamWords   float64             7\n",
            "noHost         float64             0\n",
            "numEnd           int64             0\n",
            "isYelling      float64             7\n",
            "isOrigMsg        int64             0\n",
            "isDear           int64             0\n",
            "isWrote          int64             0\n",
            "numLines         int64             0\n",
            "bodyCharCt       int64             0\n",
            "subExcCt       float64            20\n",
            "subQuesCt      float64            20\n",
            "numAtt         float64             0\n",
            "numRec         float64           282\n",
            "perCaps        float64             0\n",
            "hour           float64             0\n",
            "perHTML        float64             0\n",
            "subBlanks      float64            20\n",
            "forwards       float64             0\n",
            "avgWordLen     float64             0\n",
            "numDlr           int64             0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6UBSk_uQLAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp=SimpleImputer(missing_values=np.NaN, strategy = 'mean')\n",
        "idf=pd.DataFrame(imp.fit_transform(X))\n",
        "idf.columns=X.columns\n",
        "idf.index=X.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvTCF1XaFPuJ",
        "colab_type": "text"
      },
      "source": [
        "### Q1: BUILD/EVALUATE TREE-BASED MODEL FOR PREDICTING \"SPAM\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pClYdCBoFPuL",
        "colab_type": "code",
        "outputId": "24ba52f0-d152-405a-8a4b-da34e857b6ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, TimeSeriesSplit, StratifiedShuffleSplit\n",
        "from sklearn import metrics as mt\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(idf, y, test_size = 0.2, random_state = 101)\n",
        "\n",
        "#impute missing values for noHost and numRec using the mean from the training set\n",
        "X1_train.loc[X1_train['numRec'].isnull(),'numRec'] = X1_train.numRec.mean(skipna = True)\n",
        "X1_test.loc[X1_test['numRec'].isnull(),'numRec'] = X1_train.numRec.mean(skipna = True)\n",
        "X1_train.loc[X1_train['noHost'].isnull(),'noHost'] = X1_train.noHost.mean(skipna = True)\n",
        "X1_test.loc[X1_test['noHost'].isnull(),'noHost'] = X1_train.noHost.mean(skipna = True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv2Diu_uGdfB",
        "colab_type": "code",
        "outputId": "5ece7da5-669f-4792-833a-5059537879a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "%%time\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA \n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "gnb_clf=GaussianNB()\n",
        "gnb_clf.fit(X1_train,y1_train)\n",
        "yhatgnb = gnb_clf.predict(X1_test)\n",
        "print ('accuracy:', mt.accuracy_score(y1_test,yhatgnb))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9026737967914439\n",
            "CPU times: user 9.49 ms, sys: 1.59 ms, total: 11.1 ms\n",
            "Wall time: 14.1 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1l-HxuSMBaa",
        "colab_type": "code",
        "outputId": "efa945fd-efe4-40a1-b403-36c9a9c2f95e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "for fold, (train, test) in enumerate(cvx.split(idf,y)):\n",
        "    print ('Next Evaluation:')\n",
        "    # train the decision tree algorithm\n",
        "    gnb_clf.fit(idf.iloc[train],y[train])\n",
        "    yhat = gnb_clf.predict(idf.iloc[test])\n",
        "    print ('accuracy:', mt.accuracy_score(y[test],yhat),'\\n')\n",
        "    conf = mt.confusion_matrix(y[test],yhat)\n",
        "    print(\"confusion matrix\\n\",conf,'\\n')\n",
        "    print(\"Precision Score is: {}\" .format(precision_score(y[test],yhat, average='weighted')),'\\n')\n",
        "    print(\"Recall Score is: {}\" .format(recall_score(y[test],yhat, average='weighted')),'\\n')\n",
        "    print(\"F1 Score is: {}\" .format(f1_score(y[test],yhat, average='weighted')),'\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Next Evaluation:\n",
            "accuracy: 0.9026737967914439 \n",
            "\n",
            "confusion matrix\n",
            " [[1313   86]\n",
            " [  96  375]] \n",
            "\n",
            "Precision Score is: 0.902040547870718 \n",
            "\n",
            "Recall Score is: 0.9026737967914439 \n",
            "\n",
            "F1 Score is: 0.902324962152026 \n",
            "\n",
            "Next Evaluation:\n",
            "accuracy: 0.895187165775401 \n",
            "\n",
            "confusion matrix\n",
            " [[1314   63]\n",
            " [ 133  360]] \n",
            "\n",
            "Precision Score is: 0.8930526574691318 \n",
            "\n",
            "Recall Score is: 0.895187165775401 \n",
            "\n",
            "F1 Score is: 0.8924813344924184 \n",
            "\n",
            "Next Evaluation:\n",
            "accuracy: 0.9042780748663102 \n",
            "\n",
            "confusion matrix\n",
            " [[1296   74]\n",
            " [ 105  395]] \n",
            "\n",
            "Precision Score is: 0.9029048569386933 \n",
            "\n",
            "Recall Score is: 0.9042780748663102 \n",
            "\n",
            "F1 Score is: 0.9032823540042827 \n",
            "\n",
            "Next Evaluation:\n",
            "accuracy: 0.8946524064171123 \n",
            "\n",
            "confusion matrix\n",
            " [[1293   78]\n",
            " [ 119  380]] \n",
            "\n",
            "Precision Score is: 0.8927662297781652 \n",
            "\n",
            "Recall Score is: 0.8946524064171123 \n",
            "\n",
            "F1 Score is: 0.8931717506253282 \n",
            "\n",
            "Next Evaluation:\n",
            "accuracy: 0.9112299465240642 \n",
            "\n",
            "confusion matrix\n",
            " [[1303   65]\n",
            " [ 101  401]] \n",
            "\n",
            "Precision Score is: 0.909929563830094 \n",
            "\n",
            "Recall Score is: 0.9112299465240642 \n",
            "\n",
            "F1 Score is: 0.9101556926301699 \n",
            "\n",
            "Next Evaluation:\n",
            "accuracy: 0.8887700534759359 \n",
            "\n",
            "confusion matrix\n",
            " [[1312   78]\n",
            " [ 130  350]] \n",
            "\n",
            "Precision Score is: 0.8862092502202027 \n",
            "\n",
            "Recall Score is: 0.8887700534759359 \n",
            "\n",
            "F1 Score is: 0.8866062338947648 \n",
            "\n",
            "Next Evaluation:\n",
            "accuracy: 0.8909090909090909 \n",
            "\n",
            "confusion matrix\n",
            " [[1270   99]\n",
            " [ 105  396]] \n",
            "\n",
            "Precision Score is: 0.8905123966942149 \n",
            "\n",
            "Recall Score is: 0.8909090909090909 \n",
            "\n",
            "F1 Score is: 0.8906997723201313 \n",
            "\n",
            "Next Evaluation:\n",
            "accuracy: 0.8909090909090909 \n",
            "\n",
            "confusion matrix\n",
            " [[1308   73]\n",
            " [ 131  358]] \n",
            "\n",
            "Precision Score is: 0.8884793527812253 \n",
            "\n",
            "Recall Score is: 0.8909090909090909 \n",
            "\n",
            "F1 Score is: 0.8885922125977631 \n",
            "\n",
            "Next Evaluation:\n",
            "accuracy: 0.9026737967914439 \n",
            "\n",
            "confusion matrix\n",
            " [[1329   86]\n",
            " [  96  359]] \n",
            "\n",
            "Precision Score is: 0.9020005882036704 \n",
            "\n",
            "Recall Score is: 0.9026737967914439 \n",
            "\n",
            "F1 Score is: 0.9023044446118182 \n",
            "\n",
            "Next Evaluation:\n",
            "accuracy: 0.8898395721925134 \n",
            "\n",
            "confusion matrix\n",
            " [[1315   55]\n",
            " [ 151  349]] \n",
            "\n",
            "Precision Score is: 0.8881384085764327 \n",
            "\n",
            "Recall Score is: 0.8898395721925134 \n",
            "\n",
            "F1 Score is: 0.8858548383684048 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}